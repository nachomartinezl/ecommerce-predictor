{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11b9c24",
   "metadata": {},
   "source": [
    "# Product Classification\n",
    "\n",
    "## Evaluate your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1205a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/app/src/scripts\")\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from scripts import utils\n",
    "from scripts import efficientnet\n",
    "from scripts import resnet_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/app/src/scripts\")\n",
    "import evaluation\n",
    "from scripts.utils2 import decoder\n",
    "from scripts.build_df import build_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scripts import tree_utils\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a75b4",
   "metadata": {},
   "source": [
    "## Experiment settings\n",
    "\n",
    "Set here the two variables in the following way:\n",
    "\n",
    "- **CONFIG_YML:** assign the path to the config.yml file used for the experiment you want to evaluate\n",
    "- **WEIGHTS:** assign the path to the model weights (.h5 file) you want to evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7939dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this\n",
    "CONFIG_YML = \"/home/app/src/experiments/exp4/exp4.yml\"\n",
    "#3.5181.h5   /home/gianniif/ecommerce-predictor/experiments/exp4/model.06-2.0593.h5\n",
    "WEIGHTS = \"/home/app/src/experiments/exp4/model.06-2.0593.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc06ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 123,\n",
       " 'data': {'directory': '/home/app/src/data_splitted/train',\n",
       "  'labels': 'inferred',\n",
       "  'label_mode': 'categorical',\n",
       "  'validation_split': 0.2,\n",
       "  'image_size': [224, 224],\n",
       "  'batch_size': 32},\n",
       " 'model': {'weights': 'imagenet',\n",
       "  'input_shape': [224, 224, 3],\n",
       "  'classes': 213,\n",
       "  'dropout_rate': 0.2,\n",
       "  'data_aug_layer': {'random_flip': {'mode': 'horizontal'}}},\n",
       " 'compile': {'optimizer': {'adam': {'learning_rate': 0.001}},\n",
       "  'loss': 'categorical_crossentropy',\n",
       "  'metrics': ['accuracy']},\n",
       " 'fit': {'epochs': 150,\n",
       "  'callbacks': {'model_checkpoint': {'filepath': '/home/app/src/experiments/exp4/model.{epoch:02d}-{val_loss:.4f}.h5',\n",
       "    'save_best_only': True},\n",
       "   'tensor_board': {'log_dir': '/home/app/src/experiments/exp4/logs'}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (!) Don't touch this cell, will load the config file specified before\n",
    "config = utils.load_config(CONFIG_YML)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435199e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (!) Don't touch this cell, will use the config file to infer the class names\n",
    "#     and also to load the corresponding testing dataset.\n",
    "#     If you get an error, you must review your data/code.\n",
    "\n",
    "MODEL_CLASSES = utils.get_class_names(config)\n",
    "\n",
    "if len(MODEL_CLASSES) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your data!\"\n",
    "    )\n",
    "\n",
    "_dirname, _ = os.path.split(config['data']['directory'])\n",
    "TEST_FOLDER = os.path.join(_dirname, 'test')\n",
    "\n",
    "if not os.path.exists(TEST_FOLDER):\n",
    "    raise ValueError(\"'test' folder not found!\")\n",
    "    \n",
    "if len(os.listdir(TEST_FOLDER)) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your testing dataset!\"\n",
    "    )\n",
    "    \n",
    "if set(os.listdir(TEST_FOLDER)) != set(MODEL_CLASSES):\n",
    "    raise ValueError(\n",
    "        \"The name of the subfolders inside your test set \"\n",
    "        \"doesn't match with the model classes!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85511441",
   "metadata": {},
   "source": [
    "## Load your model\n",
    "\n",
    "Use `efficietnet.create_model()` and remember to properly setup the model weights!\n",
    "\n",
    "Assign the model to the variable `cnn_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f91894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 11:29:12.156840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.188724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.189610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.191736: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 11:29:12.192429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.193293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.194222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.800590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.801474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.802300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 11:29:12.803069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 213)               272853    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,192,165\n",
      "Trainable params: 6,131,557\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Complete this\n",
    "# TODO\n",
    "cnn_model = efficientnet.create_model(weights=WEIGHTS)\n",
    "\n",
    "# It should print your model correctly\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a33cbb",
   "metadata": {},
   "source": [
    "## Get predictions from testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce894dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 11:29:22.738049: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n",
      "2022-12-19 11:29:23.040623: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-19 11:29:23.041180: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-19 11:29:23.041233: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-12-19 11:29:23.042056: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-19 11:29:23.042342: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell, will use the loaded model and\n",
    "#     the function utils.predict_from_folder() to get \n",
    "#     model predictions and the corresponding true labels\n",
    "#     so we can measure the accuracy\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "predictions, labels = utils.predict_from_folder(\n",
    "    folder=TEST_FOLDER, \n",
    "    model=cnn_model, \n",
    "    input_size=config[\"data\"][\"image_size\"], \n",
    "    class_names=MODEL_CLASSES,\n",
    ")\n",
    "\n",
    "if len(predictions) != len(labels):\n",
    "    raise ValueError(\n",
    "        \"The lenght of predictions and labels lists doesn't match!\"\n",
    "    )\n",
    "\n",
    "if not isinstance(predictions[0], str):\n",
    "    raise ValueError(\n",
    "        \"Model predictions should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n",
    "\n",
    "if not isinstance(labels[0], str):\n",
    "    raise ValueError(\n",
    "        \"Ground true labels should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b06098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      abcat0100000       0.00      0.00      0.00        21\n",
      "      abcat0101000       0.52      0.63      0.57        19\n",
      "      abcat0101001       0.78      0.56      0.65        25\n",
      "      abcat0106004       0.38      0.75      0.50        44\n",
      "      abcat0106010       0.19      0.42      0.26        24\n",
      "      abcat0107000       0.35      0.27      0.31        41\n",
      "      abcat0107015       0.48      0.55      0.51        78\n",
      "      abcat0200000       0.44      0.50      0.47        22\n",
      "      abcat0204000       0.44      0.43      0.44        37\n",
      "      abcat0205000       1.00      0.14      0.24        59\n",
      "      abcat0205001       0.12      0.21      0.15        24\n",
      "      abcat0205006       0.58      0.58      0.58        31\n",
      "      abcat0205007       0.46      0.65      0.54        20\n",
      "      abcat0207000       0.52      0.69      0.59        70\n",
      "      abcat0208007       0.17      0.04      0.06        28\n",
      "      abcat0208015       0.22      0.12      0.16        32\n",
      "      abcat0208024       0.10      0.14      0.12        64\n",
      "      abcat0300000       0.24      0.21      0.22        43\n",
      "      abcat0301000       0.00      0.00      0.00        32\n",
      "      abcat0301006       0.48      0.79      0.60        38\n",
      "      abcat0302001       0.63      0.71      0.67        24\n",
      "      abcat0302005       0.71      0.44      0.55        27\n",
      "      abcat0302012       0.75      0.91      0.82        23\n",
      "      abcat0302037       0.76      0.57      0.65        23\n",
      "      abcat0401000       0.91      0.91      0.91        35\n",
      "      abcat0401001       0.33      0.25      0.29        20\n",
      "      abcat0409000       0.55      0.68      0.61        40\n",
      "      abcat0409001       0.88      0.81      0.85        37\n",
      "      abcat0410000       0.42      0.43      0.43        65\n",
      "      abcat0410012       0.50      0.72      0.59        25\n",
      "      abcat0410020       0.85      0.44      0.58        64\n",
      "      abcat0410022       0.31      0.26      0.28        35\n",
      "      abcat0410045       0.75      0.42      0.54        36\n",
      "      abcat0503000       0.79      0.55      0.65        42\n",
      "      abcat0504001       0.83      0.57      0.68        35\n",
      "      abcat0504010       0.67      0.73      0.70        63\n",
      "      abcat0507000       0.37      0.68      0.47        68\n",
      "      abcat0508000       0.66      0.76      0.70        74\n",
      "      abcat0509000       0.39      0.96      0.56        23\n",
      "      abcat0513004       0.90      0.90      0.90        20\n",
      "      abcat0515000       0.23      0.26      0.24        35\n",
      "      abcat0515013       0.40      0.09      0.14        23\n",
      "      abcat0515028       0.40      0.91      0.55        82\n",
      "      abcat0515042       0.39      0.75      0.51        24\n",
      "      abcat0700000       0.73      0.61      0.67        57\n",
      "      abcat0701002       0.83      0.87      0.85        39\n",
      "      abcat0703002       0.44      0.89      0.58        35\n",
      "      abcat0706000       0.94      0.73      0.82        22\n",
      "      abcat0707002       0.92      1.00      0.96        34\n",
      "      abcat0712000       0.53      0.42      0.47        24\n",
      "      abcat0715000       0.55      0.29      0.37        21\n",
      "      abcat0800000       0.75      0.67      0.71        49\n",
      "      abcat0802000       0.89      0.30      0.44        27\n",
      "      abcat0805000       0.68      0.47      0.56        32\n",
      "      abcat0807001       0.87      0.87      0.87        99\n",
      "      abcat0807009       0.93      0.86      0.89        64\n",
      "      abcat0809000       0.21      0.48      0.29        27\n",
      "      abcat0809002       0.87      0.92      0.89        37\n",
      "      abcat0809004       0.53      0.61      0.57        28\n",
      "      abcat0811002       0.54      0.25      0.34        56\n",
      "      abcat0811004       0.39      0.34      0.37        44\n",
      "      abcat0811006       0.87      0.83      0.85       361\n",
      "      abcat0811007       0.52      0.71      0.60        68\n",
      "      abcat0811011       0.43      0.55      0.48        22\n",
      "      abcat0900000       0.81      0.65      0.72        20\n",
      "      abcat0901000       0.29      0.75      0.42        56\n",
      "      abcat0902000       0.61      0.70      0.66        27\n",
      "      abcat0904001       0.94      0.88      0.91        51\n",
      "      abcat0904004       0.56      1.00      0.72        23\n",
      "      abcat0905001       0.89      0.96      0.93        52\n",
      "      abcat0907001       0.75      0.67      0.71        27\n",
      "      abcat0907006       0.83      0.81      0.82        48\n",
      "      abcat0907007       0.65      0.47      0.55        32\n",
      "      abcat0908001       0.27      0.39      0.32        23\n",
      "      abcat0908003       0.94      0.57      0.71        28\n",
      "      abcat0910001       0.74      0.96      0.83        26\n",
      "      abcat0911000       0.69      0.84      0.76        67\n",
      "      abcat0912000       0.48      0.40      0.44        73\n",
      "      abcat0912005       0.43      0.45      0.44        20\n",
      "      abcat0912008       1.00      0.62      0.76        21\n",
      "      abcat0912012       0.89      0.57      0.69        30\n",
      "      abcat0912014       0.67      0.10      0.17        21\n",
      "      abcat0912018       1.00      0.74      0.85        39\n",
      "      abcat0912020       0.64      0.75      0.69        24\n",
      "      abcat0912023       1.00      0.66      0.79        29\n",
      "      abcat0912025       0.45      0.44      0.45        43\n",
      "      abcat0915000       1.00      0.29      0.45        41\n",
      "      abcat0915005       0.82      0.48      0.61        29\n",
      "      abcat0915009       0.75      0.09      0.16        34\n",
      "      abcat0916000       0.38      0.53      0.45        62\n",
      "      abcat0916008       0.37      0.42      0.40        38\n",
      "          cat09000       0.98      0.97      0.97        91\n",
      "             other       0.32      0.35      0.34       538\n",
      "pcmcat128500050004       0.78      0.17      0.29        40\n",
      "pcmcat138500050001       1.00      0.60      0.75        30\n",
      "pcmcat143000050007       0.85      0.86      0.86        74\n",
      "pcmcat143200050025       1.00      0.08      0.15        25\n",
      "pcmcat143400050013       0.79      0.80      0.79        74\n",
      "pcmcat144700050004       0.00      0.00      0.00        26\n",
      "pcmcat151600050008       0.72      0.34      0.46        38\n",
      "pcmcat151600050027       0.88      0.71      0.79        21\n",
      "pcmcat151600050037       0.62      0.84      0.71        19\n",
      "pcmcat152100050010       0.43      0.70      0.53        33\n",
      "pcmcat152100050020       0.32      0.40      0.36        55\n",
      "pcmcat152100050027       0.32      0.38      0.35        32\n",
      "pcmcat152100050035       0.17      0.12      0.14        33\n",
      "pcmcat152100050038       0.58      0.53      0.55        36\n",
      "pcmcat152200050014       0.00      0.00      0.00        20\n",
      "pcmcat156300050006       0.24      0.28      0.26        32\n",
      "pcmcat158900050018       0.94      0.68      0.79        25\n",
      "pcmcat158900050019       0.92      1.00      0.96        22\n",
      "pcmcat159300050002       0.74      0.81      0.77        21\n",
      "pcmcat165900050023       0.30      0.11      0.16        28\n",
      "pcmcat165900050032       0.41      0.33      0.37        21\n",
      "pcmcat165900050033       0.66      0.90      0.76       148\n",
      "pcmcat165900050034       0.56      0.59      0.57        34\n",
      "pcmcat171900050024       0.31      0.45      0.37        20\n",
      "pcmcat171900050026       1.00      0.05      0.09        21\n",
      "pcmcat171900050031       0.82      0.56      0.67        25\n",
      "pcmcat179200050003       0.92      0.39      0.55        31\n",
      "pcmcat179200050008       0.76      0.58      0.66        45\n",
      "pcmcat179200050013       0.92      0.60      0.73        20\n",
      "pcmcat180700050008       0.75      0.55      0.63        22\n",
      "pcmcat183800050006       0.80      0.92      0.86        52\n",
      "pcmcat183800050007       0.83      0.45      0.59        22\n",
      "pcmcat186100050005       0.33      0.67      0.44        21\n",
      "pcmcat191200050015       0.64      0.19      0.29        37\n",
      "pcmcat194000050018       0.43      0.64      0.52        25\n",
      "pcmcat194000050022       0.55      0.30      0.38        61\n",
      "pcmcat194000050023       0.81      0.74      0.77        23\n",
      "pcmcat195200050001       0.50      0.05      0.10        19\n",
      "pcmcat196400050015       0.87      0.98      0.92        56\n",
      "pcmcat196400050016       0.95      0.92      0.93        60\n",
      "pcmcat200900050014       0.00      0.00      0.00        31\n",
      "pcmcat202800050013       0.65      0.90      0.75       124\n",
      "pcmcat207200050007       0.67      0.79      0.73        42\n",
      "pcmcat209000050006       0.93      0.74      0.82        19\n",
      "pcmcat209000050008       0.56      0.88      0.68        43\n",
      "pcmcat209400050001       0.92      0.67      0.77        33\n",
      "pcmcat210000050008       0.38      0.67      0.48        36\n",
      "pcmcat210900050000       1.00      0.37      0.54        19\n",
      "pcmcat210900050001       0.23      0.90      0.37        21\n",
      "pcmcat214700050000       0.72      0.92      0.80       284\n",
      "pcmcat219100050010       0.73      0.79      0.76        34\n",
      "pcmcat221100050003       1.00      0.05      0.10        20\n",
      "pcmcat225800050009       0.50      0.65      0.57        20\n",
      "pcmcat226900050013       0.91      0.31      0.46        97\n",
      "pcmcat232900050000       0.82      0.75      0.78        24\n",
      "pcmcat232900050017       0.99      0.92      0.95       711\n",
      "pcmcat232900050030       0.00      0.00      0.00        23\n",
      "pcmcat232900050031       0.55      0.88      0.68        26\n",
      "pcmcat233000050008       0.34      0.87      0.49        30\n",
      "pcmcat240500050052       0.70      0.26      0.38        27\n",
      "pcmcat240500050057       0.29      0.14      0.19        28\n",
      "pcmcat241600050001       0.14      0.17      0.15        24\n",
      "pcmcat242000050002       0.79      0.45      0.57       103\n",
      "pcmcat242800050021       1.00      0.03      0.06        35\n",
      "pcmcat244200050008       0.50      0.37      0.43        27\n",
      "pcmcat247400050000       0.72      0.98      0.83        51\n",
      "pcmcat248300050003       1.00      0.31      0.47        29\n",
      "pcmcat249700050006       0.30      0.28      0.29        25\n",
      "pcmcat251300050004       0.72      0.38      0.50        69\n",
      "pcmcat251500050009       0.53      0.42      0.47        24\n",
      "pcmcat251600050003       0.25      0.10      0.14        20\n",
      "pcmcat252700050006       0.65      0.40      0.49        55\n",
      "pcmcat254000050002       0.39      0.42      0.40        57\n",
      "pcmcat258900050003       0.61      0.83      0.70        23\n",
      "pcmcat258900050007       0.71      0.19      0.29        27\n",
      "pcmcat266500050030       0.80      0.90      0.85        40\n",
      "pcmcat268100050002       0.29      0.64      0.40        28\n",
      "pcmcat272800050000       0.56      0.86      0.68        29\n",
      "pcmcat284400050091       0.75      0.57      0.65        21\n",
      "pcmcat284800050006       0.12      0.04      0.06        27\n",
      "pcmcat284800050007       0.59      0.75      0.66        44\n",
      "pcmcat286300050020       0.72      0.72      0.72        25\n",
      "pcmcat296300050018       0.71      0.94      0.81        51\n",
      "pcmcat300300050002       0.40      0.32      0.35        19\n",
      "pcmcat303600050001       0.65      0.78      0.71        36\n",
      "pcmcat303600050005       0.84      0.86      0.85        43\n",
      "pcmcat303700050016       0.58      0.33      0.42        21\n",
      "pcmcat306400050032       0.79      0.90      0.84        49\n",
      "pcmcat308100050020       0.55      0.67      0.60        27\n",
      "pcmcat309300050002       0.56      0.62      0.59        29\n",
      "pcmcat309300050003       0.00      0.00      0.00        20\n",
      "pcmcat309900050001       0.34      0.46      0.39        57\n",
      "pcmcat310200050004       0.62      0.59      0.60       135\n",
      "pcmcat311200050005       0.82      0.72      0.77        58\n",
      "pcmcat312300050015       0.44      0.39      0.41        31\n",
      "pcmcat324200050004       0.65      0.81      0.72        21\n",
      "pcmcat326000050010       0.44      0.72      0.55        68\n",
      "pcmcat326000050011       0.74      0.96      0.83        47\n",
      "pcmcat328900050008       0.75      0.27      0.40        33\n",
      "pcmcat331200050000       0.79      0.32      0.46        34\n",
      "pcmcat331200050001       0.32      0.86      0.46        36\n",
      "pcmcat331600050007       0.31      0.47      0.37        51\n",
      "pcmcat332100050000       0.65      0.88      0.75        80\n",
      "pcmcat335400050008       0.94      0.96      0.95        47\n",
      "pcmcat338200050008       0.68      0.79      0.73        19\n",
      "pcmcat340500050007       0.87      0.83      0.85        24\n",
      "pcmcat344400050007       0.42      0.63      0.50        52\n",
      "pcmcat350800050010       0.93      0.83      0.88        47\n",
      "pcmcat352500050007       0.68      0.36      0.47        36\n",
      "pcmcat367400050001       0.64      0.21      0.31       135\n",
      "pcmcat367400050002       0.72      0.47      0.57        45\n",
      "pcmcat369900050001       0.64      0.23      0.34        30\n",
      "pcmcat373300050003       0.68      0.57      0.62        23\n",
      "pcmcat374500050006       0.00      0.00      0.00        17\n",
      "pcmcat377500050003       0.73      0.73      0.73        26\n",
      "pcmcat748300322875       0.80      0.83      0.82        24\n",
      "pcmcat748300579994       0.00      0.00      0.00        24\n",
      "pcmcat748300580023       0.52      0.55      0.53        42\n",
      "pcmcat748301695443       0.76      0.69      0.72        36\n",
      "pcmcat748301803023       0.92      0.82      0.87        57\n",
      "\n",
      "          accuracy                           0.61     10006\n",
      "         macro avg       0.60      0.55      0.54     10006\n",
      "      weighted avg       0.64      0.61      0.60     10006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell\n",
    "\n",
    "print(classification_report(y_true=labels, y_pred=predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2379d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories\n",
      "├── pcmcat312300050015\n",
      "│   ├── pcmcat248700050021\n",
      "│   │   ├── pcmcat303600050001\n",
      "│   │   └── pcmcat179100050006\n",
      "│   │       ├── pcmcat179200050003\n",
      "│   │       ├── pcmcat179200050008\n",
      "│   │       │   └── pcmcat748300322875\n",
      "│   │       └── pcmcat179200050013\n",
      "│   ├── abcat0802000\n",
      "│   │   ├── abcat0811011\n",
      "│   │   └── abcat0802001\n",
      "│   │       └── pcmcat159300050002\n",
      "│   ├── abcat0805000\n",
      "│   │   └── abcat0511001\n",
      "│   │       └── pcmcat266500050030\n",
      "│   ├── pcmcat275600050000\n",
      "│   │   └── abcat0807000\n",
      "│   │       ├── abcat0807001\n",
      "│   │       ├── pcmcat335400050008\n",
      "│   │       └── abcat0807009\n",
      "│   ├── abcat0809000\n",
      "│   │   ├── abcat0809004\n",
      "│   │   └── abcat0809002\n",
      "│   ├── pcmcat249700050006\n",
      "│   │   ├── pcmcat219100050010\n",
      "│   │   ├── pcmcat286300050020\n",
      "│   │   └── pcmcat272800050000\n",
      "│   ├── pcmcat254000050002\n",
      "│   │   └── pcmcat308100050020\n",
      "│   │       └── pcmcat340500050007\n",
      "│   └── pcmcat341100050005\n",
      "│       └── pcmcat253700050018\n",
      "│           └── pcmcat248300050003\n",
      "├── other\n",
      "├── abcat0300000\n",
      "│   ├── pcmcat165900050023\n",
      "│   │   └── pcmcat331600050007\n",
      "│   │       └── pcmcat165900050031\n",
      "│   │           ├── pcmcat165900050033\n",
      "│   │           ├── pcmcat165900050034\n",
      "│   │           └── pcmcat165900050032\n",
      "│   ├── abcat0302000\n",
      "│   │   ├── abcat0302034\n",
      "│   │   │   └── abcat0302037\n",
      "│   │   ├── abcat0302001\n",
      "│   │   ├── abcat0302012\n",
      "│   │   └── abcat0302005\n",
      "│   ├── pcmcat156300050006\n",
      "│   └── abcat0301000\n",
      "├── abcat0207000\n",
      "│   ├── pcmcat152100050020\n",
      "│   ├── abcat0208024\n",
      "│   │   └── pcmcat151600050008\n",
      "│   ├── pcmcat152100050035\n",
      "│   │   └── pcmcat251600050003\n",
      "│   │       └── pcmcat152100050038\n",
      "│   ├── pcmcat151600050037\n",
      "│   ├── pcmcat152100050027\n",
      "│   ├── pcmcat152200050014\n",
      "│   │   ├── pcmcat202800050013\n",
      "│   │   └── pcmcat251500050009\n",
      "│   ├── pcmcat152100050010\n",
      "│   └── pcmcat151600050019\n",
      "│       └── pcmcat221400050011\n",
      "│           └── pcmcat151600050027\n",
      "├── pcmcat252700050006\n",
      "│   ├── pcmcat244200050008\n",
      "│   ├── pcmcat284400050091\n",
      "│   └── pcmcat369900050001\n",
      "├── abcat0700000\n",
      "│   ├── abcat0706000\n",
      "│   ├── abcat0701000\n",
      "│   │   └── abcat0701002\n",
      "│   ├── pcmcat232900050017\n",
      "│   ├── abcat0707000\n",
      "│   │   └── abcat0707002\n",
      "│   ├── abcat0703000\n",
      "│   │   └── abcat0703002\n",
      "│   ├── abcat0712000\n",
      "│   ├── pcmcat232900050000\n",
      "│   ├── abcat0715000\n",
      "│   ├── pcmcat295700050012\n",
      "│   │   └── pcmcat296300050018\n",
      "│   ├── pcmcat300300050002\n",
      "│   │   └── pcmcat303600050005\n",
      "│   └── pcmcat306400050032\n",
      "├── abcat0400000\n",
      "│   ├── abcat0401000\n",
      "│   │   └── abcat0401001\n",
      "│   │       └── pcmcat324200050004\n",
      "│   ├── abcat0410022\n",
      "│   │   └── pcmcat329700050009\n",
      "│   │       └── pcmcat240500050057\n",
      "│   ├── abcat0410000\n",
      "│   │   ├── abcat0410018\n",
      "│   │   │   ├── pcmcat233000050008\n",
      "│   │   │   │   └── pcmcat195200050001\n",
      "│   │   │   └── pcmcat374500050006\n",
      "│   │   ├── abcat0410020\n",
      "│   │   ├── abcat0410012\n",
      "│   │   │   └── pcmcat284800050007\n",
      "│   │   ├── pcmcat284800050006\n",
      "│   │   │   └── abcat0410001\n",
      "│   │   │       └── pcmcat328900050008\n",
      "│   │   ├── abcat0410045\n",
      "│   │   └── pcmcat240500050025\n",
      "│   │       └── pcmcat240500050052\n",
      "│   ├── abcat0404000\n",
      "│   │   └── pcmcat225800050009\n",
      "│   └── abcat0409000\n",
      "│       └── abcat0409001\n",
      "├── abcat0500000\n",
      "│   ├── abcat0515000\n",
      "│   │   ├── abcat0515042\n",
      "│   │   ├── pcmcat221100050003\n",
      "│   │   ├── abcat0515025\n",
      "│   │   │   ├── pcmcat183800050007\n",
      "│   │   │   ├── pcmcat183800050006\n",
      "│   │   │   └── abcat0515028\n",
      "│   │   ├── abcat0513000\n",
      "│   │   │   ├── pcmcat338200050008\n",
      "│   │   │   └── abcat0513004\n",
      "│   │   ├── abcat0504001\n",
      "│   │   │   └── pcmcat186100050005\n",
      "│   │   ├── abcat0504010\n",
      "│   │   └── abcat0515012\n",
      "│   │       └── abcat0515013\n",
      "│   ├── abcat0507000\n",
      "│   ├── pcmcat309900050001\n",
      "│   │   └── pcmcat242000050002\n",
      "│   │       └── pcmcat344400050007\n",
      "│   ├── abcat0509000\n",
      "│   │   └── pcmcat200900050014\n",
      "│   ├── abcat0508000\n",
      "│   ├── pcmcat209000050006\n",
      "│   │   └── pcmcat209000050008\n",
      "│   ├── abcat0503000\n",
      "│   ├── abcat0502000\n",
      "│   │   └── pcmcat138500050001\n",
      "│   │       └── pcmcat247400050000\n",
      "│   └── abcat0501000\n",
      "│       └── pcmcat143400050013\n",
      "├── abcat0900000\n",
      "│   ├── abcat0904000\n",
      "│   │   ├── abcat0904001\n",
      "│   │   ├── abcat0904004\n",
      "│   │   │   └── pcmcat180700050008\n",
      "│   │   ├── abcat0904003\n",
      "│   │   │   ├── pcmcat196400050015\n",
      "│   │   │   └── pcmcat196400050016\n",
      "│   │   └── abcat0904002\n",
      "│   │       └── pcmcat207200050007\n",
      "│   ├── abcat0912000\n",
      "│   │   ├── pcmcat367400050002\n",
      "│   │   │   ├── pcmcat367400050005\n",
      "│   │   │   │   └── abcat0912008\n",
      "│   │   │   ├── abcat0912005\n",
      "│   │   │   │   └── pcmcat258900050007\n",
      "│   │   │   └── pcmcat367400050003\n",
      "│   │   │       └── pcmcat194000050023\n",
      "│   │   ├── abcat0912011\n",
      "│   │   │   └── pcmcat194000050018\n",
      "│   │   │       └── pcmcat258900050003\n",
      "│   │   ├── abcat0912014\n",
      "│   │   ├── abcat0912025\n",
      "│   │   │   └── pcmcat251300050004\n",
      "│   │   ├── abcat0912023\n",
      "│   │   ├── abcat0912012\n",
      "│   │   ├── abcat0912020\n",
      "│   │   ├── pcmcat748301695371\n",
      "│   │   │   ├── pcmcat226900050013\n",
      "│   │   │   └── pcmcat748301695443\n",
      "│   │   ├── abcat0912018\n",
      "│   │   └── pcmcat194000050022\n",
      "│   ├── abcat0902000\n",
      "│   ├── pcmcat302300050021\n",
      "│   │   ├── abcat0907001\n",
      "│   │   ├── abcat0907007\n",
      "│   │   ├── abcat0908003\n",
      "│   │   ├── abcat0908001\n",
      "│   │   ├── pcmcat268100050002\n",
      "│   │   └── abcat0907006\n",
      "│   ├── abcat0901000\n",
      "│   │   └── pcmcat367400050001\n",
      "│   ├── abcat0903000\n",
      "│   │   └── pcmcat748301803023\n",
      "│   ├── abcat0910000\n",
      "│   │   ├── abcat0910004\n",
      "│   │   │   ├── pcmcat232900050031\n",
      "│   │   │   └── pcmcat232900050030\n",
      "│   │   └── abcat0910001\n",
      "│   ├── abcat0911000\n",
      "│   ├── abcat0905000\n",
      "│   │   └── abcat0905001\n",
      "│   └── abcat0916000\n",
      "│       ├── pcmcat303700050016\n",
      "│       └── abcat0916008\n",
      "├── abcat0200000\n",
      "│   ├── abcat0204000\n",
      "│   │   ├── pcmcat144700050004\n",
      "│   │   ├── pcmcat143000050011\n",
      "│   │   │   ├── pcmcat331200050001\n",
      "│   │   │   └── pcmcat331200050000\n",
      "│   │   └── pcmcat143000050007\n",
      "│   ├── pcmcat241600050001\n",
      "│   │   ├── pcmcat309300050002\n",
      "│   │   ├── abcat0205000\n",
      "│   │   │   ├── abcat0205006\n",
      "│   │   │   ├── pcmcat210900050000\n",
      "│   │   │   │   └── pcmcat210900050001\n",
      "│   │   │   └── abcat0205001\n",
      "│   │   ├── abcat0203000\n",
      "│   │   │   └── abcat0205007\n",
      "│   │   └── pcmcat309300050003\n",
      "│   ├── abcat0208007\n",
      "│   ├── pcmcat310200050004\n",
      "│   └── abcat0208000\n",
      "│       └── abcat0208015\n",
      "├── abcat0100000\n",
      "│   ├── abcat0106000\n",
      "│   │   ├── pcmcat332100050008\n",
      "│   │   │   └── pcmcat158900050019\n",
      "│   │   ├── abcat0106004\n",
      "│   │   ├── abcat0106001\n",
      "│   │   │   └── pcmcat332100050000\n",
      "│   │   └── abcat0106010\n",
      "│   ├── abcat0107000\n",
      "│   │   └── abcat0107015\n",
      "│   ├── abcat0101000\n",
      "│   │   └── abcat0101001\n",
      "│   └── pcmcat158900050008\n",
      "│       └── pcmcat158900050018\n",
      "├── pcmcat242800050021\n",
      "│   ├── abcat0915000\n",
      "│   │   ├── abcat0915009\n",
      "│   │   └── abcat0915005\n",
      "│   ├── pcmcat352500050007\n",
      "│   ├── abcat0301006\n",
      "│   └── pcmcat210000050008\n",
      "├── pcmcat128500050004\n",
      "├── abcat0800000\n",
      "│   ├── abcat0811002\n",
      "│   │   ├── abcat0811006\n",
      "│   │   ├── pcmcat191200050015\n",
      "│   │   │   └── pcmcat214700050000\n",
      "│   │   │       ├── pcmcat748300579994\n",
      "│   │   │       └── pcmcat748300580023\n",
      "│   │   ├── abcat0811004\n",
      "│   │   │   ├── pcmcat326000050010\n",
      "│   │   │   └── pcmcat326000050011\n",
      "│   │   ├── pcmcat373300050003\n",
      "│   │   ├── abcat0811007\n",
      "│   │   │   ├── pcmcat171900050026\n",
      "│   │   │   └── pcmcat171900050024\n",
      "│   │   ├── pcmcat171900050031\n",
      "│   │   └── pcmcat321000050003\n",
      "│   │       └── pcmcat321000050005\n",
      "│   │           └── pcmcat350800050010\n",
      "│   ├── pcmcat156400050037\n",
      "│   │   └── pcmcat311200050005\n",
      "│   └── pcmcat209400050001\n",
      "├── cat09000\n",
      "├── pcmcat139900050002\n",
      "│   └── pcmcat748300660981\n",
      "│       └── pcmcat143200050025\n",
      "└── pcmcat332000050000\n",
      "    └── pcmcat748300489081\n",
      "        └── pcmcat377500050002\n",
      "            └── pcmcat377500050003\n"
     ]
    }
   ],
   "source": [
    "cat = build_df(json_path='products.json', \n",
    "             threshold=100, \n",
    "             preprocessed_csv='normalized_data.csv'\n",
    "            ) \n",
    "\n",
    "y = cat['leaf']\n",
    "\n",
    "tree_dict = tree_utils.make_tree(cat, cat['category'], 'Categories', display_tree= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3b862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36d95fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                           \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtree_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/scripts/evaluation.py:36\u001b[0m, in \u001b[0;36mget_performance\u001b[0;34m(model, pred_labels, true_labels, probs, average, tree, vectorizer)\u001b[0m\n\u001b[1;32m     34\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mf1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39maverage)\n\u001b[1;32m     35\u001b[0m report \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mclassification_report(y_true, y_pred)\n\u001b[0;32m---> 36\u001b[0m top_k_score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k_accuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m dict_report_id \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mclassification_report(true_labels, pred_labels, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/experiments/exp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1729\u001b[0m, in \u001b[0;36mtop_k_accuracy_score\u001b[0;34m(y_true, y_score, k, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1727\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my type must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1728\u001b[0m     )\n\u001b[0;32m-> 1729\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:887\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead."
     ]
    }
   ],
   "source": [
    "evaluation.get_performance(model=cnn_model,\n",
    "                           pred_labels=predictions, \n",
    "                           true_labels=labels,\n",
    "                           probs=predictions,\n",
    "                           average='micro',\n",
    "                           tree= tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8342c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model accuracy is 0.6102!\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell\n",
    "\n",
    "acc = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "\n",
    "print(f\"Your model accuracy is {acc:.4f}!\")\n",
    "\n",
    "if acc < .3:\n",
    "    raise ValueError(\"Your model accuracy is too low :(\\nYou can do it better! :)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee5563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
