{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[nltk_data] Downloading package stopwords to /home/app/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from model.text_normalizer import normalize_corpus, stopword_list\n",
    "from model import evaluation\n",
    "from model.utils import decoder\n",
    "from scripts.build_df import build_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scripts import tree_utils\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import dump, load\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In future training you will be able to proceed without performing again the normalization step:\n",
    "\n",
    "```python\n",
    "\n",
    "df = pd.read_csv('data/normalized_data.csv')\n",
    "\n",
    "name = df['name'].apply(str)\n",
    "description = df['description'].apply(str)\n",
    "name_and_description = df['name_and_description'].apply(str)\n",
    "\n",
    "# Select X depending on which data you are going to use to train your model\n",
    "X = name\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels and features selection\n",
    "`X` will vary depending if we choose name, description or name_and_description as feature.\n",
    "\n",
    "**Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/normalized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = df['name'].apply(str)\n",
    "description = df['description'].apply(str)\n",
    "name_and_description = df['name_and_description'].apply(str)\n",
    "X1 = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 duracel aaa batteri 4pack\n",
       "1    duracel aa 15v coppertop batteri 4pack\n",
       "2                  duracel aa batteri 8pack\n",
       "3                energ max batteri aa 4pack\n",
       "4                   duracel c batteri 4pack\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labels**\n",
    "\n",
    "`build_df()` function returns a new dataset with custom leaf (label) according to the threshold of min. products selected per category.\n",
    "\n",
    "Call `build_df()` to extract the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = build_df(json_path='data/products.json', \n",
    "             threshold=100, \n",
    "             preprocessed_csv='data/normalized_data.csv'\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cat['leaf']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the hierarchical structure of our categories applying our `make_tree()` function\n",
    "\n",
    "We extracted the nodes from the same dataframe generated by `build_df()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories\n",
      "├── pcmcat312300050015\n",
      "│   ├── pcmcat248700050021\n",
      "│   │   ├── pcmcat303600050001\n",
      "│   │   └── pcmcat179100050006\n",
      "│   │       ├── pcmcat179200050003\n",
      "│   │       ├── pcmcat179200050008\n",
      "│   │       │   └── pcmcat748300322875\n",
      "│   │       └── pcmcat179200050013\n",
      "│   ├── abcat0802000\n",
      "│   │   ├── abcat0811011\n",
      "│   │   └── abcat0802001\n",
      "│   │       └── pcmcat159300050002\n",
      "│   ├── abcat0805000\n",
      "│   │   └── abcat0511001\n",
      "│   │       └── pcmcat266500050030\n",
      "│   ├── pcmcat275600050000\n",
      "│   │   └── abcat0807000\n",
      "│   │       ├── abcat0807001\n",
      "│   │       ├── pcmcat335400050008\n",
      "│   │       └── abcat0807009\n",
      "│   ├── abcat0809000\n",
      "│   │   ├── abcat0809004\n",
      "│   │   └── abcat0809002\n",
      "│   ├── pcmcat249700050006\n",
      "│   │   ├── pcmcat219100050010\n",
      "│   │   ├── pcmcat286300050020\n",
      "│   │   └── pcmcat272800050000\n",
      "│   ├── pcmcat254000050002\n",
      "│   │   └── pcmcat308100050020\n",
      "│   │       └── pcmcat340500050007\n",
      "│   └── pcmcat341100050005\n",
      "│       └── pcmcat253700050018\n",
      "│           └── pcmcat248300050003\n",
      "├── other\n",
      "├── abcat0300000\n",
      "│   ├── pcmcat165900050023\n",
      "│   │   └── pcmcat331600050007\n",
      "│   │       └── pcmcat165900050031\n",
      "│   │           ├── pcmcat165900050033\n",
      "│   │           ├── pcmcat165900050034\n",
      "│   │           └── pcmcat165900050032\n",
      "│   ├── abcat0302000\n",
      "│   │   ├── abcat0302034\n",
      "│   │   │   └── abcat0302037\n",
      "│   │   ├── abcat0302001\n",
      "│   │   ├── abcat0302012\n",
      "│   │   └── abcat0302005\n",
      "│   ├── pcmcat156300050006\n",
      "│   └── abcat0301000\n",
      "├── abcat0207000\n",
      "│   ├── pcmcat152100050020\n",
      "│   ├── abcat0208024\n",
      "│   │   └── pcmcat151600050008\n",
      "│   ├── pcmcat152100050035\n",
      "│   │   └── pcmcat251600050003\n",
      "│   │       └── pcmcat152100050038\n",
      "│   ├── pcmcat151600050037\n",
      "│   ├── pcmcat152100050027\n",
      "│   ├── pcmcat152200050014\n",
      "│   │   ├── pcmcat202800050013\n",
      "│   │   └── pcmcat251500050009\n",
      "│   ├── pcmcat152100050010\n",
      "│   └── pcmcat151600050019\n",
      "│       └── pcmcat221400050011\n",
      "│           └── pcmcat151600050027\n",
      "├── pcmcat252700050006\n",
      "│   ├── pcmcat244200050008\n",
      "│   ├── pcmcat284400050091\n",
      "│   └── pcmcat369900050001\n",
      "├── abcat0700000\n",
      "│   ├── abcat0706000\n",
      "│   ├── abcat0701000\n",
      "│   │   └── abcat0701002\n",
      "│   ├── pcmcat232900050017\n",
      "│   ├── abcat0707000\n",
      "│   │   └── abcat0707002\n",
      "│   ├── abcat0703000\n",
      "│   │   └── abcat0703002\n",
      "│   ├── abcat0712000\n",
      "│   ├── pcmcat232900050000\n",
      "│   ├── abcat0715000\n",
      "│   ├── pcmcat295700050012\n",
      "│   │   └── pcmcat296300050018\n",
      "│   ├── pcmcat300300050002\n",
      "│   │   └── pcmcat303600050005\n",
      "│   └── pcmcat306400050032\n",
      "├── abcat0400000\n",
      "│   ├── abcat0401000\n",
      "│   │   └── abcat0401001\n",
      "│   │       └── pcmcat324200050004\n",
      "│   ├── abcat0410022\n",
      "│   │   └── pcmcat329700050009\n",
      "│   │       └── pcmcat240500050057\n",
      "│   ├── abcat0410000\n",
      "│   │   ├── abcat0410018\n",
      "│   │   │   ├── pcmcat233000050008\n",
      "│   │   │   │   └── pcmcat195200050001\n",
      "│   │   │   └── pcmcat374500050006\n",
      "│   │   ├── abcat0410020\n",
      "│   │   ├── abcat0410012\n",
      "│   │   │   └── pcmcat284800050007\n",
      "│   │   ├── pcmcat284800050006\n",
      "│   │   │   └── abcat0410001\n",
      "│   │   │       └── pcmcat328900050008\n",
      "│   │   ├── abcat0410045\n",
      "│   │   └── pcmcat240500050025\n",
      "│   │       └── pcmcat240500050052\n",
      "│   ├── abcat0404000\n",
      "│   │   └── pcmcat225800050009\n",
      "│   └── abcat0409000\n",
      "│       └── abcat0409001\n",
      "├── abcat0500000\n",
      "│   ├── abcat0515000\n",
      "│   │   ├── abcat0515042\n",
      "│   │   ├── pcmcat221100050003\n",
      "│   │   ├── abcat0515025\n",
      "│   │   │   ├── pcmcat183800050007\n",
      "│   │   │   ├── pcmcat183800050006\n",
      "│   │   │   └── abcat0515028\n",
      "│   │   ├── abcat0513000\n",
      "│   │   │   ├── pcmcat338200050008\n",
      "│   │   │   └── abcat0513004\n",
      "│   │   ├── abcat0504001\n",
      "│   │   │   └── pcmcat186100050005\n",
      "│   │   ├── abcat0504010\n",
      "│   │   └── abcat0515012\n",
      "│   │       └── abcat0515013\n",
      "│   ├── abcat0507000\n",
      "│   ├── pcmcat309900050001\n",
      "│   │   └── pcmcat242000050002\n",
      "│   │       └── pcmcat344400050007\n",
      "│   ├── abcat0509000\n",
      "│   │   └── pcmcat200900050014\n",
      "│   ├── abcat0508000\n",
      "│   ├── pcmcat209000050006\n",
      "│   │   └── pcmcat209000050008\n",
      "│   ├── abcat0503000\n",
      "│   ├── abcat0502000\n",
      "│   │   └── pcmcat138500050001\n",
      "│   │       └── pcmcat247400050000\n",
      "│   └── abcat0501000\n",
      "│       └── pcmcat143400050013\n",
      "├── abcat0900000\n",
      "│   ├── abcat0904000\n",
      "│   │   ├── abcat0904001\n",
      "│   │   ├── abcat0904004\n",
      "│   │   │   └── pcmcat180700050008\n",
      "│   │   ├── abcat0904003\n",
      "│   │   │   ├── pcmcat196400050015\n",
      "│   │   │   └── pcmcat196400050016\n",
      "│   │   └── abcat0904002\n",
      "│   │       └── pcmcat207200050007\n",
      "│   ├── abcat0912000\n",
      "│   │   ├── pcmcat367400050002\n",
      "│   │   │   ├── pcmcat367400050005\n",
      "│   │   │   │   └── abcat0912008\n",
      "│   │   │   ├── abcat0912005\n",
      "│   │   │   │   └── pcmcat258900050007\n",
      "│   │   │   └── pcmcat367400050003\n",
      "│   │   │       └── pcmcat194000050023\n",
      "│   │   ├── abcat0912011\n",
      "│   │   │   └── pcmcat194000050018\n",
      "│   │   │       └── pcmcat258900050003\n",
      "│   │   ├── abcat0912014\n",
      "│   │   ├── abcat0912025\n",
      "│   │   │   └── pcmcat251300050004\n",
      "│   │   ├── abcat0912023\n",
      "│   │   ├── abcat0912012\n",
      "│   │   ├── abcat0912020\n",
      "│   │   ├── pcmcat748301695371\n",
      "│   │   │   ├── pcmcat226900050013\n",
      "│   │   │   └── pcmcat748301695443\n",
      "│   │   ├── abcat0912018\n",
      "│   │   └── pcmcat194000050022\n",
      "│   ├── abcat0902000\n",
      "│   ├── pcmcat302300050021\n",
      "│   │   ├── abcat0907001\n",
      "│   │   ├── abcat0907007\n",
      "│   │   ├── abcat0908003\n",
      "│   │   ├── abcat0908001\n",
      "│   │   ├── pcmcat268100050002\n",
      "│   │   └── abcat0907006\n",
      "│   ├── abcat0901000\n",
      "│   │   └── pcmcat367400050001\n",
      "│   ├── abcat0903000\n",
      "│   │   └── pcmcat748301803023\n",
      "│   ├── abcat0910000\n",
      "│   │   ├── abcat0910004\n",
      "│   │   │   ├── pcmcat232900050031\n",
      "│   │   │   └── pcmcat232900050030\n",
      "│   │   └── abcat0910001\n",
      "│   ├── abcat0911000\n",
      "│   ├── abcat0905000\n",
      "│   │   └── abcat0905001\n",
      "│   └── abcat0916000\n",
      "│       ├── pcmcat303700050016\n",
      "│       └── abcat0916008\n",
      "├── abcat0200000\n",
      "│   ├── abcat0204000\n",
      "│   │   ├── pcmcat144700050004\n",
      "│   │   ├── pcmcat143000050011\n",
      "│   │   │   ├── pcmcat331200050001\n",
      "│   │   │   └── pcmcat331200050000\n",
      "│   │   └── pcmcat143000050007\n",
      "│   ├── pcmcat241600050001\n",
      "│   │   ├── pcmcat309300050002\n",
      "│   │   ├── abcat0205000\n",
      "│   │   │   ├── abcat0205006\n",
      "│   │   │   ├── pcmcat210900050000\n",
      "│   │   │   │   └── pcmcat210900050001\n",
      "│   │   │   └── abcat0205001\n",
      "│   │   ├── abcat0203000\n",
      "│   │   │   └── abcat0205007\n",
      "│   │   └── pcmcat309300050003\n",
      "│   ├── abcat0208007\n",
      "│   ├── pcmcat310200050004\n",
      "│   └── abcat0208000\n",
      "│       └── abcat0208015\n",
      "├── abcat0100000\n",
      "│   ├── abcat0106000\n",
      "│   │   ├── pcmcat332100050008\n",
      "│   │   │   └── pcmcat158900050019\n",
      "│   │   ├── abcat0106004\n",
      "│   │   ├── abcat0106001\n",
      "│   │   │   └── pcmcat332100050000\n",
      "│   │   └── abcat0106010\n",
      "│   ├── abcat0107000\n",
      "│   │   └── abcat0107015\n",
      "│   ├── abcat0101000\n",
      "│   │   └── abcat0101001\n",
      "│   └── pcmcat158900050008\n",
      "│       └── pcmcat158900050018\n",
      "├── pcmcat242800050021\n",
      "│   ├── abcat0915000\n",
      "│   │   ├── abcat0915009\n",
      "│   │   └── abcat0915005\n",
      "│   ├── pcmcat352500050007\n",
      "│   ├── abcat0301006\n",
      "│   └── pcmcat210000050008\n",
      "├── pcmcat128500050004\n",
      "├── abcat0800000\n",
      "│   ├── abcat0811002\n",
      "│   │   ├── abcat0811006\n",
      "│   │   ├── pcmcat191200050015\n",
      "│   │   │   └── pcmcat214700050000\n",
      "│   │   │       ├── pcmcat748300579994\n",
      "│   │   │       └── pcmcat748300580023\n",
      "│   │   ├── abcat0811004\n",
      "│   │   │   ├── pcmcat326000050010\n",
      "│   │   │   └── pcmcat326000050011\n",
      "│   │   ├── pcmcat373300050003\n",
      "│   │   ├── abcat0811007\n",
      "│   │   │   ├── pcmcat171900050026\n",
      "│   │   │   └── pcmcat171900050024\n",
      "│   │   ├── pcmcat171900050031\n",
      "│   │   └── pcmcat321000050003\n",
      "│   │       └── pcmcat321000050005\n",
      "│   │           └── pcmcat350800050010\n",
      "│   ├── pcmcat156400050037\n",
      "│   │   └── pcmcat311200050005\n",
      "│   └── pcmcat209400050001\n",
      "├── cat09000\n",
      "├── pcmcat139900050002\n",
      "│   └── pcmcat748300660981\n",
      "│       └── pcmcat143200050025\n",
      "└── pcmcat332000050000\n",
      "    └── pcmcat748300489081\n",
      "        └── pcmcat377500050002\n",
      "            └── pcmcat377500050003\n"
     ]
    }
   ],
   "source": [
    "tree_dict = tree_utils.make_tree(cat, cat['category'], 'Categories', display_tree= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**:\n",
    "- Generate the labels and the tree in the **same step**. If you do not do that you will not be allowed to get the distance between predicted and true categories when apply `get_performance()` function \n",
    "\n",
    "- `make_tree()` print the tree if you set `display_tree= True`. `display_tree= False` only generates the tree structure (without printing it) and the dictionary of nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict2 = tree_utils.make_tree(cat, cat['category'], 'Categories', display_tree= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y_train, y_test = train_test_split(\n",
    "    X1, y,\n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7029                conair suprem 2in1 hot air brush white\n",
       "26164    hp slimlin desktop intel pentium 4gb memori 50...\n",
       "46217    mb quart discu 1200w class sq ab bridgeabl 2ch...\n",
       "13187                  sabr window glass alarm 2pack white\n",
       "41483                   elit beat agent preown nintendo ds\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Try different values for `max_features` and `ngram_range` in TF-IDF. Also experimenting with and without IDF and min and max idf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(max_features=2500,\n",
    "                                  ngram_range=(1, 2),\n",
    "                                  use_idf=False,\n",
    "                                  min_df=1,\n",
    "                                  norm='l2',\n",
    "                                  smooth_idf=True\n",
    "                                 ) \n",
    "X_train1 = tfid_vectorizer.fit_transform(X1_train)\n",
    "X_test1 = tfid_vectorizer.transform(X1_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of categories with the highest probability \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression(max_iter=500, \n",
    "                            n_jobs=-1, \n",
    "                            multi_class='multinomial',\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='multinomial', n_jobs=-1,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1.fit(X_train1, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtaining predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test1 = logreg1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcmcat151600050037'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted category at row 0\n",
    "y_pred_test1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.21029133e-03 3.12719967e-04 2.67706225e-04 ... 2.69329639e-04\n",
      "  6.72509490e-04 2.94944043e-04]\n",
      " [7.93442120e-04 5.04152150e-04 4.26394467e-04 ... 4.35679191e-04\n",
      "  1.29535994e-03 5.22190961e-04]\n",
      " [6.15516769e-04 3.78380902e-04 3.23508929e-04 ... 3.32110473e-04\n",
      "  8.76119972e-04 3.99408449e-04]\n",
      " ...\n",
      " [2.07738770e-03 4.94625242e-04 5.99770125e-04 ... 3.79268905e-04\n",
      "  5.95326660e-04 5.06579978e-04]\n",
      " [4.34331351e-04 9.88657452e-05 1.09903021e-04 ... 1.06812889e-04\n",
      "  1.43549006e-04 1.03057694e-04]\n",
      " [1.09467275e-03 2.16377464e-04 2.84401241e-04 ... 1.42695700e-04\n",
      "  2.53156018e-04 2.20185454e-04]]\n"
     ]
    }
   ],
   "source": [
    "#probabilities of each category\n",
    "y_pred_test1_p = logreg1.predict_proba(X_test1)\n",
    "\n",
    "#Let's see the array of probabilities for the first row:\n",
    "print(y_pred_test1_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look for the index of the highest value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# index of the category with the highest probability \n",
    "idx_max_prob = np.argmax(y_pred_test1_p[0])\n",
    "print(idx_max_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass the index to the array of classes, we can obtain the name of the category with the highest probability. We can see that it matches with the predicted category by `log_reg1.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcmcat151600050037\n",
      "pcmcat151600050037\n"
     ]
    }
   ],
   "source": [
    "print(logreg1.classes_[101]) #name obtained by accesing classes in predict_proba()\n",
    "print(y_pred_test1[0]) #category name obtained by predict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: obtain indexes class of the five most probable predicted categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101  92  39  16  60]\n"
     ]
    }
   ],
   "source": [
    "most_prob_cat_idx = np.argsort(-y_pred_test1_p[0])[:5]\n",
    "print(most_prob_cat_idx)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we pass those index to `classes_` and saved the names of the categories with the highest probabilities in a list :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pcmcat151600050037', 'other', 'abcat0513004', 'abcat0208024', 'abcat0811004']\n"
     ]
    }
   ],
   "source": [
    "name_cat_most_prob= []\n",
    "for idx in most_prob_cat_idx:\n",
    "    nm_cat = logreg1.classes_[idx]\n",
    "    name_cat_most_prob.append(nm_cat)\n",
    "\n",
    "print(name_cat_most_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
