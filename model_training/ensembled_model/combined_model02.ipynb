{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG Model\n",
    "\n",
    "In this notebook, we perform our first exploration of the combination of different models previously trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = [1, 5, 45]\n",
    "1/len(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m     22\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "#from model.text_normalizer import normalize_corpus, stopword_list\n",
    "from model import evaluation\n",
    "from model.utils2 import decoder\n",
    "from scripts.build_df import build_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scripts import tree_utils\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/app/src/model\")\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from model import evaluation\n",
    "from model import utils\n",
    "import os\n",
    "os.chdir(\"/home/app/src/images/scripts\")\n",
    "import efficientnet\n",
    "import os\n",
    "os.chdir(\"/home/app/src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Pre-Trained Models (BL0 and BL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Household Batteries',\n",
       " '2': 'Software',\n",
       " '3': 'Cell Phone Batteries & Power',\n",
       " '4': 'Connected Home',\n",
       " '5': 'other'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_feat_max(cat_prob, prod_idx, max_k_feat, classes):\n",
    "    \"\"\"Given a array of predicted probability of classes for one product returns a dictionary with the names of the k classes with the highest probability\"\"\"\n",
    "    most_prob_cat_idx = np.argsort(-cat_prob[prod_idx][0])[:max_k_feat]\n",
    "    name_cat_max= []\n",
    "    \n",
    "    for idx in most_prob_cat_idx:\n",
    "      nm_cat = classes[idx]\n",
    "      name_cat_max.append(nm_cat)\n",
    "\n",
    "    dict_max_feat = {}\n",
    "    for items in range(len(name_cat_max)):\n",
    "        dict_max_feat[str(items+1)] = np.array_str(decoder(name_cat_max[items]))\n",
    "\n",
    "    return dict_max_feat\n",
    "\n",
    "\n",
    "    # categories model A\n",
    "dict_a = get_feat_max(cat_prob= probs,\n",
    "                      prod_idx= 0,\n",
    "                      max_k_feat=5,\n",
    "                      classes= MODEL_CLASSES)\n",
    "dict_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 213)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from model.text_normalizer import normalize_corpus, stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening\n",
    "#model = joblib.load('model_name')\n",
    "model_title = joblib.load('/home/app/src/model/model_BL0')\n",
    "vect_title  = joblib.load('/home/app/src/model/vect_BL0')\n",
    "\n",
    "model_title_desc = joblib.load('/home/app/src/model/model_BL1')\n",
    "vect_title_desc = joblib.load('/home/app/src/model/vect_BL1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(input):\n",
    "    output = normalize_corpus(\n",
    "        input,\n",
    "        html_stripping=True,\n",
    "        contraction_expansion=True,\n",
    "        accented_char_removal=True,\n",
    "        text_lower_case=True,\n",
    "        text_stemming=True,\n",
    "        text_lemmatization=False,\n",
    "        special_char_removal=True,\n",
    "        remove_digits=False,\n",
    "        stopword_removal=True,\n",
    "        stopwords=stopword_list\n",
    "    )       \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sample = \"Casio - Portable Keyboard with 61 Touch-Sensitive Keys - Black/Silver \"\n",
    "descr_sample = \"CASIO Portable Keyboard with 61 Touch-Sensitive Keys: MIDI and USB connectivity; 600 AHL keyboard voices; 180 rhythms; 152 songs; auto accompaniment\"\n",
    "name_descr_sample = name_sample + descr_sample\n",
    "true_label_sample = 'Keyboards'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sample_n = normalize_corpus([name_sample])\n",
    "name_sample_v= vect_title.transform(name_sample_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_descr_sample_n = normalize_corpus([name_descr_sample])\n",
    "name_descr_sample_v= vect_title_desc.transform(name_descr_sample_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create combined model to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Model():\n",
    "   \n",
    "\n",
    "    def predict_proba(self, X_list, estimators):\n",
    "        \"\"\"\n",
    "        Predict probabilities of classes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of array_like or sparse matrix of shape (n_samples, n_features)\n",
    "            [X_name, X_description, X_image]\n",
    "        estimators: list of pretrained models to be combined in the following order [name_model, name_description_model, image_model]\n",
    "        Returns\n",
    "        -------\n",
    "        C : array, shape [n_samples]\n",
    "            Predicted class label per sample.\n",
    "        \"\"\"\n",
    "        # only NLP Models \n",
    "        if len(estimators) == 2:\n",
    "            y_pred_model_1 = estimators[0].predict_proba(X_list[0])\n",
    "            y_pred_model_2 = estimators[1].predict_proba(X_list[1])\n",
    "            probs = np.array([(prob1 + prob2) * 0.5 for prob1, prob2 in zip(y_pred_model_1, y_pred_model_2)])\n",
    "        \n",
    "        # NLP + images    \n",
    "        elif len(estimators) == 3:\n",
    "            y_pred_model_1 = estimators[0].predict_proba(X_list[0])\n",
    "            y_pred_model_2 = estimators[1].predict_proba(X_list[1])\n",
    "            y_pred_model_3 = estimators[2].predict_proba(X_list[2])\n",
    "            probs = np.array([(prob1 + prob2+ prob3) * (1/len(estimators)) for prob1, prob2, prob3 in zip(y_pred_model_1, y_pred_model_2, y_pred_model_3)])\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def predict_best_five(self, X_list, estimators, max_k_feat):\n",
    "        \"\"\"\n",
    "        Selects the k classes with highest probability for samples in X_list obtained from predict_proba() method .\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        X_list : list of array_like or sparse matrix of shape (n_samples, n_features)\n",
    "            [X_name, X_description, X_image] to pass to predict_proba()\n",
    "        estimators: list of pretrained models to be combined in the following order [name_model, name_description_model, image_model]\n",
    "        Returns\n",
    "\n",
    "        estimators : list List of models to be combined\n",
    "\n",
    "        max_k_feat : int number of classes\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        dict_max_feat: python dict dictionary with classes with highest probability\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        probs = self.predict_proba(X_list, estimators)\n",
    "\n",
    "        cat_prob = probs\n",
    "        classes = estimators[0].classes_\n",
    "\n",
    "        most_prob_cat_idx = np.argsort(-cat_prob[0])[:max_k_feat]\n",
    "        name_cat_max= []\n",
    "    \n",
    "        for idx in most_prob_cat_idx:\n",
    "            nm_cat = classes[idx]\n",
    "            name_cat_max.append(nm_cat)\n",
    "\n",
    "        dict_max_feat = {}\n",
    "        for items in range(len(name_cat_max)):\n",
    "          dict_max_feat[items] = np.array_str(decoder(name_cat_max[items]))\n",
    "\n",
    "        return dict_max_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Combined_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = final_model.predict_best_five(X_list=[name_sample_v, name_descr_sample_v], \n",
    "                                           estimators=[model_title, model_title_desc], \n",
    "                                           max_k_feat=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Keyboards',\n",
       " 1: 'Computer Keyboards',\n",
       " 2: 'Musical Instrument Accessories',\n",
       " 3: 'other',\n",
       " 4: 'iPad & Tablet Accessories'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
