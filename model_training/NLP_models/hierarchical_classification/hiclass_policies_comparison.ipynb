{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiClass Policies Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/app/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/app/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer\n",
    "import hiclass.metrics\n",
    "from sklearn import metrics\n",
    "from scripts.build_df import build_df\n",
    "from scripts.decode_id import decode_id\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from os import cpu_count\n",
    "from hiclass import LocalClassifierPerNode, LocalClassifierPerParentNode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base df and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(input):\n",
    "    output = text_normalizer.normalize_corpus(\n",
    "        input,\n",
    "        html_stripping=True,\n",
    "        contraction_expansion=True,\n",
    "        accented_char_removal=True,\n",
    "        text_lower_case=True,\n",
    "        text_stemming=True,\n",
    "        text_lemmatization=False,\n",
    "        special_char_removal=True,\n",
    "        remove_digits=False,\n",
    "        stopword_removal=True,\n",
    "        stopwords=text_normalizer.stopword_list\n",
    "    )       \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function for creating new columns\n",
    "def assign_precision(x):\n",
    "    return hiclass.metrics.precision(x[0:1], x[1:2])\n",
    "def assign_recall(x):\n",
    "    return hiclass.metrics.recall(x[0:1], x[1:2])\n",
    "def assign_f1(x):\n",
    "    # Condition to avoid ZeroDivisionError\n",
    "    if x[\"precision\"] * x[\"recall\"] == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 2 * x[\"precision\"] * x[\"recall\"] / (x[\"precision\"] + x[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dataframe\n",
    "no_threshold_df = build_df(json_path='data/products.json', threshold=0) \n",
    "\n",
    "# Train test split\n",
    "X = no_threshold_df['name'].copy()\n",
    "X = normalization(X.apply(str))\n",
    "y = no_threshold_df['path'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Initialize vectorizer\n",
    "tfid_vectorizer = TfidfVectorizer(ngram_range=(1, 2)) \n",
    "X_train = tfid_vectorizer.fit_transform(X_train)\n",
    "X_test = tfid_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comparison_df = pd.DataFrame(columns=[\"train_failures\", \"train_precision\", \"train_recall\", \"train_f1\"])\n",
    "test_comparison_df = pd.DataFrame(columns=[\"test_failures\", \"test_precision\", \"test_recall\", \"test_f1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies_dict = {\n",
    "    0 : \"exclusive\",\n",
    "    1 : \"less_exclusive\",\n",
    "    2 : \"less_inclusive\",\n",
    "    3 : \"inclusive\",\n",
    "    4 : \"siblings\",\n",
    "    5 : \"exclusive_siblings\"\n",
    "}\n",
    "\n",
    "rename_dict = policies_dict\n",
    "rename_dict[6] = \"parent_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:44:21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m hierarchical_classifier \u001b[39m=\u001b[39m hiclass\u001b[39m.\u001b[39mLocalClassifierPerNode(binary_policy\u001b[39m=\u001b[39mpolicies_dict[i],n_jobs\u001b[39m=\u001b[39mcpu_count(), local_classifier\u001b[39m=\u001b[39mrandom_forest)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Train hierarchical classifier\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m hierarchical_classifier\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Store training time\u001b[39;00m\n\u001b[1;32m     13\u001b[0m training_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m starting_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hiclass/LocalClassifierPerNode.py:116\u001b[0m, in \u001b[0;36mLocalClassifierPerNode.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_binary_policy()\n\u001b[1;32m    115\u001b[0m \u001b[39m# Fit local classifiers in DAG\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m    118\u001b[0m \u001b[39m# TODO: Store the classes seen during fit\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[39m# TODO: Add function to allow user to change local classifier\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39m# Return the classifier\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hiclass/HierarchicalClassifier.py:124\u001b[0m, in \u001b[0;36mHierarchicalClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39mFit a local hierarchical classifier.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# Fit local classifiers in DAG\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_digraph()\n\u001b[1;32m    126\u001b[0m \u001b[39m# Delete unnecessary variables\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clean_up()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hiclass/LocalClassifierPerNode.py:227\u001b[0m, in \u001b[0;36mLocalClassifierPerNode._fit_digraph\u001b[0;34m(self, local_mode, use_joblib)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m# Remove root because it does not need to be fitted\u001b[39;00m\n\u001b[1;32m    226\u001b[0m nodes\u001b[39m.\u001b[39mremove(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_)\n\u001b[0;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_node_classifier(nodes, local_mode, use_joblib)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hiclass/HierarchicalClassifier.py:324\u001b[0m, in \u001b[0;36mHierarchicalClassifier._fit_node_classifier\u001b[0;34m(self, nodes, local_mode, use_joblib)\u001b[0m\n\u001b[1;32m    322\u001b[0m         classifiers \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(results)\n\u001b[1;32m    323\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m         classifiers \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    325\u001b[0m             delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_classifier)(\u001b[39mself\u001b[39;49m, node) \u001b[39mfor\u001b[39;49;00m node \u001b[39min\u001b[39;49;00m nodes\n\u001b[1;32m    326\u001b[0m         )\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     classifiers \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_classifier(\u001b[39mself\u001b[39m, node) \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in policies_dict:\n",
    "    # Initialize timer\n",
    "    starting_time = time.time()\n",
    "\n",
    "    # Initialize model\n",
    "    random_forest = RandomForestClassifier(random_state=42)\n",
    "    # Initialize hierarchical classifier with model\n",
    "    hierarchical_classifier = hiclass.LocalClassifierPerNode(binary_policy=policies_dict[i],n_jobs=cpu_count(), local_classifier=random_forest)\n",
    "    # Train hierarchical classifier\n",
    "    hierarchical_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Store training time\n",
    "    training_time = time.time() - starting_time\n",
    "    training_time = time.strftime(\"%H:%M:%S\", time.gmtime(training_time))\n",
    "\n",
    "    # Predict on train and test\n",
    "    y_pred_train = hierarchical_classifier.predict(X_train)\n",
    "    y_pred_test = hierarchical_classifier.predict(X_test)\n",
    "\n",
    "    # Train_df\n",
    "    train_df = pd.DataFrame(y_train)\n",
    "    train_df[\"prediction\"] = pd.Series(y_pred_train.tolist(), index = train_df.index)\n",
    "    train_df[\"precision\"] = train_df.apply(lambda x: assign_precision(x), axis=1)\n",
    "    train_df[\"recall\"] = train_df.apply(lambda x: assign_recall(x), axis=1)\n",
    "    train_df[\"f1\"] = train_df.apply(lambda x: assign_f1(x), axis=1)\n",
    "    train_df[\"training_time\"] = training_time\n",
    "    \n",
    "    # Test_df\n",
    "    test_df = pd.DataFrame(y_test)\n",
    "    test_df[\"prediction\"] = pd.Series(y_pred_test.tolist(), index = test_df.index)\n",
    "    test_df[\"precision\"] = test_df.apply(lambda x: assign_precision(x), axis=1)\n",
    "    test_df[\"recall\"] = test_df.apply(lambda x: assign_recall(x), axis=1)\n",
    "    test_df[\"f1\"] = test_df.apply(lambda x: assign_f1(x), axis=1)\n",
    "    test_df[\"training_time\"] = training_time\n",
    "\n",
    "    # Save results\n",
    "    results_train = [\n",
    "        len(train_df[\"f1\"][train_df[\"f1\"] == 0.0]),\n",
    "        hiclass.metrics.precision(y_train, y_pred_train),\n",
    "        hiclass.metrics.recall(y_train, y_pred_train),\n",
    "        hiclass.metrics.f1(y_train, y_pred_train)\n",
    "        ]\n",
    "\n",
    "    train_comparison_df.loc[len(train_comparison_df)] = results_train\n",
    "\n",
    "    results_test = [\n",
    "        len(test_df[\"f1\"][test_df[\"f1\"] == 0.0]),\n",
    "        hiclass.metrics.precision(y_test, y_pred_test),\n",
    "        hiclass.metrics.recall(y_test, y_pred_test),\n",
    "        hiclass.metrics.f1(y_test, y_pred_test)\n",
    "        ]\n",
    "\n",
    "    test_comparison_df.loc[len(test_comparison_df)] = results_test\n",
    "    print(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize timer\n",
    "starting_time = time.time()\n",
    "\n",
    "# Initialize model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "# Initialize hierarchical classifier with model\n",
    "hierarchical_classifier = hiclass.LocalClassifierPerParentNode(n_jobs=cpu_count(), local_classifier=random_forest)\n",
    "# Train hierarchical classifier\n",
    "hierarchical_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Store training time\n",
    "training_time = time.time() - starting_time\n",
    "training_time = time.strftime(\"%H:%M:%S\", time.gmtime(training_time))\n",
    "\n",
    "# Predict on train and test\n",
    "y_pred_train = hierarchical_classifier.predict(X_train)\n",
    "y_pred_test = hierarchical_classifier.predict(X_test)\n",
    "\n",
    "# Train_df\n",
    "train_df = pd.DataFrame(y_train)\n",
    "train_df[\"prediction\"] = pd.Series(y_pred_train.tolist(), index = train_df.index)\n",
    "train_df[\"precision\"] = train_df.apply(lambda x: assign_precision(x), axis=1)\n",
    "train_df[\"recall\"] = train_df.apply(lambda x: assign_recall(x), axis=1)\n",
    "train_df[\"f1\"] = train_df.apply(lambda x: assign_f1(x), axis=1)\n",
    "train_df[\"training_time\"] = training_time\n",
    "\n",
    "# Test_df\n",
    "test_df = pd.DataFrame(y_test)\n",
    "test_df[\"prediction\"] = pd.Series(y_pred_test.tolist(), index = test_df.index)\n",
    "test_df[\"precision\"] = test_df.apply(lambda x: assign_precision(x), axis=1)\n",
    "test_df[\"recall\"] = test_df.apply(lambda x: assign_recall(x), axis=1)\n",
    "test_df[\"f1\"] = test_df.apply(lambda x: assign_f1(x), axis=1)\n",
    "test_df[\"training_time\"] = training_time\n",
    "\n",
    "# Save results\n",
    "results_train = [\n",
    "    len(train_df[\"f1\"][train_df[\"f1\"] == 0.0]),\n",
    "    hiclass.metrics.precision(y_train, y_pred_train),\n",
    "    hiclass.metrics.recall(y_train, y_pred_train),\n",
    "    hiclass.metrics.f1(y_train, y_pred_train)\n",
    "    ]\n",
    "\n",
    "train_comparison_df.loc[len(train_comparison_df)] = results_train\n",
    "\n",
    "results_test = [\n",
    "    len(test_df[\"f1\"][test_df[\"f1\"] == 0.0]),\n",
    "    hiclass.metrics.precision(y_test, y_pred_test),\n",
    "    hiclass.metrics.recall(y_test, y_pred_test),\n",
    "    hiclass.metrics.f1(y_test, y_pred_test)\n",
    "    ]\n",
    "\n",
    "test_comparison_df.loc[len(test_comparison_df)] = results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_failures</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exclusive</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.932178</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>0.963418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_failures  train_precision  train_recall  train_f1\n",
       "exclusive            28.0         0.932178      0.996824  0.963418"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparison_df.rename(index=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_failures</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exclusive</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.843235</td>\n",
       "      <td>0.904365</td>\n",
       "      <td>0.872731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_failures  test_precision  test_recall   test_f1\n",
       "exclusive          400.0        0.843235     0.904365  0.872731"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comparison_df.rename(index=rename_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
