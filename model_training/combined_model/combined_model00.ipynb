{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG Model\n",
    "\n",
    "In this notebook, we perform our first exploration of the combination of different models previously trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[nltk_data] Downloading package stopwords to /home/app/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from model.text_normalizer import normalize_corpus, stopword_list\n",
    "from model import evaluation\n",
    "from model.utils import decoder\n",
    "from scripts.build_df import build_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scripts import tree_utils\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Pre-Trained Models (BL0 and BL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from model.text_normalizer import normalize_corpus, stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening\n",
    "#model = joblib.load('model_name')\n",
    "model_title = joblib.load('/home/app/src/model/model_BL0')\n",
    "vect_title  = joblib.load('/home/app/src/model/vect_BL0')\n",
    "\n",
    "model_title_desc = joblib.load('/home/app/src/model/model_BL1')\n",
    "vect_title_desc = joblib.load('/home/app/src/model/vect_BL1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(input):\n",
    "    output = normalize_corpus(\n",
    "        input,\n",
    "        html_stripping=True,\n",
    "        contraction_expansion=True,\n",
    "        accented_char_removal=True,\n",
    "        text_lower_case=True,\n",
    "        text_stemming=True,\n",
    "        text_lemmatization=False,\n",
    "        special_char_removal=True,\n",
    "        remove_digits=False,\n",
    "        stopword_removal=True,\n",
    "        stopwords=stopword_list\n",
    "    )       \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sample = \"Casio - Portable Keyboard with 61 Touch-Sensitive Keys - Black/Silver \"\n",
    "descr_sample = \"CASIO Portable Keyboard with 61 Touch-Sensitive Keys: MIDI and USB connectivity; 600 AHL keyboard voices; 180 rhythms; 152 songs; auto accompaniment\"\n",
    "name_descr_sample = name_sample + descr_sample\n",
    "true_label_sample = 'Keyboards'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sample_n = normalize_corpus([name_sample])\n",
    "name_sample_v= vect_title.transform(name_sample_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_descr_sample_n = normalize_corpus([name_descr_sample])\n",
    "name_descr_sample_v= vect_title_desc.transform(name_descr_sample_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create combined model to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Model():\n",
    "   \n",
    "\n",
    "    def predict_proba(self, X_list, estimators):\n",
    "        \"\"\"\n",
    "        Predict probabilities of classes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of array_like or sparse matrix of shape (n_samples, n_features)\n",
    "            [X_name, X_description, X_image]\n",
    "        estimators: list of pretrained models to be combined in the following order [name_model, name_description_model, image_model]\n",
    "        Returns\n",
    "        -------\n",
    "        C : array, shape [n_samples]\n",
    "            Predicted class label per sample.\n",
    "        \"\"\"\n",
    "        # only NLP Models \n",
    "        if len(estimators) == 2:\n",
    "            y_pred_model_1 = estimators[0].predict_proba(X_list[0])\n",
    "            y_pred_model_2 = estimators[1].predict_proba(X_list[1])\n",
    "            probs = np.array([(prob1 + prob2) * 0.5 for prob1, prob2 in zip(y_pred_model_1, y_pred_model_2)])\n",
    "        \n",
    "        # NLP + images    \n",
    "        elif len(estimators) == 3:\n",
    "            y_pred_model_1 = estimators[0].predict_proba(X_list[0])\n",
    "            y_pred_model_2 = estimators[1].predict_proba(X_list[1])\n",
    "            y_pred_model_3 = estimators[2].predict_proba(X_list[2])\n",
    "            probs = np.array([(prob1 + prob2+ prob3) * (1/len(estimators)) for prob1, prob2, prob3 in zip(y_pred_model_1, y_pred_model_2, y_pred_model_3)])\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def predict_best_five(self, X_list, estimators, max_k_feat):\n",
    "        \"\"\"\n",
    "        Selects the k classes with highest probability for samples in X_list obtained from predict_proba() method .\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        X_list : list of array_like or sparse matrix of shape (n_samples, n_features)\n",
    "            [X_name, X_description, X_image] to pass to predict_proba()\n",
    "        estimators: list of pretrained models to be combined in the following order [name_model, name_description_model, image_model]\n",
    "        Returns\n",
    "\n",
    "        estimators : list List of models to be combined\n",
    "\n",
    "        max_k_feat : int number of classes\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        dict_max_feat: python dict dictionary with classes with highest probability\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        probs = self.predict_proba(X_list, estimators)\n",
    "\n",
    "        cat_prob = probs\n",
    "        classes = estimators[0].classes_\n",
    "\n",
    "        most_prob_cat_idx = np.argsort(-cat_prob[0])[:max_k_feat]\n",
    "        name_cat_max= []\n",
    "    \n",
    "        for idx in most_prob_cat_idx:\n",
    "            nm_cat = classes[idx]\n",
    "            name_cat_max.append(nm_cat)\n",
    "\n",
    "        dict_max_feat = {}\n",
    "        for items in range(len(name_cat_max)):\n",
    "          dict_max_feat[items] = np.array_str(decoder(name_cat_max[items]))\n",
    "\n",
    "        return dict_max_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Combined_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = final_model.predict_best_five(X_list=[name_sample_v, name_descr_sample_v], \n",
    "                                           estimators=[model_title, model_title_desc], \n",
    "                                           max_k_feat=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Keyboards',\n",
       " 1: 'Computer Keyboards',\n",
       " 2: 'Musical Instrument Accessories',\n",
       " 3: 'other',\n",
       " 4: 'iPad & Tablet Accessories'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
