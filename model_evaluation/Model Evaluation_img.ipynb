{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11b9c24",
   "metadata": {},
   "source": [
    "# Product Classification\n",
    "\n",
    "## Evaluate your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1205a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"/home/app/src/utils\")\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from utils import evaluation\n",
    "from utils import utils\n",
    "from utils.utils_img import decoder\n",
    "\n",
    "from utils import efficientnet\n",
    "from utils import resnet_50\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utils.build_df import build_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import tree_utils\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import dump, load\n",
    "import os\n",
    "os.chdir(\"/home/app/src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a75b4",
   "metadata": {},
   "source": [
    "## Experiment settings\n",
    "\n",
    "Set here the two variables in the following way:\n",
    "\n",
    "- **CONFIG_YML:** assign the path to the config.yml file used for the experiment you want to evaluate\n",
    "- **WEIGHTS:** assign the path to the model weights (.h5 file) you want to evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7939dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this\n",
    "\n",
    "CONFIG_YML = \"/home/app/src/model_training/CV_models/exp4/exp4.yml\"\n",
    "#3.5181.h5   /home/gianniif/ecommerce-predictor/experiments/exp4/model.06-2.0593.h5\n",
    "WEIGHTS = \"/home/app/src/model/model.06-2.0593.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc06ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 123,\n",
       " 'data': {'directory': '/home/app/src/data_splitted/train',\n",
       "  'labels': 'inferred',\n",
       "  'label_mode': 'categorical',\n",
       "  'validation_split': 0.2,\n",
       "  'image_size': [224, 224],\n",
       "  'batch_size': 32},\n",
       " 'model': {'weights': 'imagenet',\n",
       "  'input_shape': [224, 224, 3],\n",
       "  'classes': 213,\n",
       "  'dropout_rate': 0.2,\n",
       "  'data_aug_layer': {'random_flip': {'mode': 'horizontal'}}},\n",
       " 'compile': {'optimizer': {'adam': {'learning_rate': 0.001}},\n",
       "  'loss': 'categorical_crossentropy',\n",
       "  'metrics': ['accuracy']},\n",
       " 'fit': {'epochs': 150,\n",
       "  'callbacks': {'model_checkpoint': {'filepath': '/home/app/src/experiments/exp4/model.{epoch:02d}-{val_loss:.4f}.h5',\n",
       "    'save_best_only': True},\n",
       "   'tensor_board': {'log_dir': '/home/app/src/experiments/exp4/logs'}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (!) Don't touch this cell, will load the config file specified before\n",
    "config = utils.load_config(CONFIG_YML)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435199e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (!) Don't touch this cell, will use the config file to infer the class names\n",
    "#     and also to load the corresponding testing dataset.\n",
    "#     If you get an error, you must review your data/code.\n",
    "\n",
    "MODEL_CLASSES = utils.get_class_names(config)\n",
    "\n",
    "if len(MODEL_CLASSES) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your data!\"\n",
    "    )\n",
    "\n",
    "_dirname, _ = os.path.split(config['data']['directory'])\n",
    "TEST_FOLDER = os.path.join(_dirname, 'test')\n",
    "\n",
    "if not os.path.exists(TEST_FOLDER):\n",
    "    raise ValueError(\"'test' folder not found!\")\n",
    "    \n",
    "if len(os.listdir(TEST_FOLDER)) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your testing dataset!\"\n",
    "    )\n",
    "    \n",
    "if set(os.listdir(TEST_FOLDER)) != set(MODEL_CLASSES):\n",
    "    raise ValueError(\n",
    "        \"The name of the subfolders inside your test set \"\n",
    "        \"doesn't match with the model classes!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85511441",
   "metadata": {},
   "source": [
    "## Load your model\n",
    "\n",
    "Use `efficietnet.create_model()` and remember to properly setup the model weights!\n",
    "\n",
    "Assign the model to the variable `cnn_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f91894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 02:31:24.508556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:24.517332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:24.518172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:24.520194: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 02:31:24.520808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:24.521757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:24.522694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:25.120982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:25.121839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:25.122648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 02:31:25.123403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 213)               272853    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,192,165\n",
      "Trainable params: 6,131,557\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Complete this\n",
    "# TODO\n",
    "cnn_model = efficientnet.create_model(weights=WEIGHTS)\n",
    "\n",
    "# It should print your model correctly\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a33cbb",
   "metadata": {},
   "source": [
    "## Get predictions from testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce894dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 02:31:36.420593: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n",
      "2022-12-20 02:31:36.709582: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-20 02:31:36.710115: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-20 02:31:36.710168: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-12-20 02:31:36.710818: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-20 02:31:36.710955: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell, will use the loaded model and\n",
    "#     the function utils.predict_from_folder() to get \n",
    "#     model predictions and the corresponding true labels\n",
    "#     so we can measure the accuracy\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "predictions, labels, probs = utils_img.predict_from_folder(\n",
    "    folder=TEST_FOLDER, \n",
    "    model=cnn_model, \n",
    "    input_size=config[\"data\"][\"image_size\"], \n",
    "    class_names=MODEL_CLASSES,\n",
    ")\n",
    "\n",
    "if len(predictions) != len(labels):\n",
    "    raise ValueError(\n",
    "        \"The lenght of predictions and labels lists doesn't match!\"\n",
    "    )\n",
    "\n",
    "if not isinstance(predictions[0], str):\n",
    "    raise ValueError(\n",
    "        \"Model predictions should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n",
    "\n",
    "if not isinstance(labels[0], str):\n",
    "    raise ValueError(\n",
    "        \"Ground true labels should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0138695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45109c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs= np.array(probs).reshape(-1, 213)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b06098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      abcat0100000       0.00      0.00      0.00        21\n",
      "      abcat0101000       0.52      0.63      0.57        19\n",
      "      abcat0101001       0.78      0.56      0.65        25\n",
      "      abcat0106004       0.38      0.75      0.50        44\n",
      "      abcat0106010       0.19      0.42      0.26        24\n",
      "      abcat0107000       0.35      0.27      0.31        41\n",
      "      abcat0107015       0.48      0.55      0.51        78\n",
      "      abcat0200000       0.44      0.50      0.47        22\n",
      "      abcat0204000       0.44      0.43      0.44        37\n",
      "      abcat0205000       1.00      0.14      0.24        59\n",
      "      abcat0205001       0.12      0.21      0.15        24\n",
      "      abcat0205006       0.58      0.58      0.58        31\n",
      "      abcat0205007       0.46      0.65      0.54        20\n",
      "      abcat0207000       0.52      0.69      0.59        70\n",
      "      abcat0208007       0.17      0.04      0.06        28\n",
      "      abcat0208015       0.22      0.12      0.16        32\n",
      "      abcat0208024       0.10      0.14      0.12        64\n",
      "      abcat0300000       0.24      0.21      0.22        43\n",
      "      abcat0301000       0.00      0.00      0.00        32\n",
      "      abcat0301006       0.48      0.79      0.60        38\n",
      "      abcat0302001       0.63      0.71      0.67        24\n",
      "      abcat0302005       0.71      0.44      0.55        27\n",
      "      abcat0302012       0.75      0.91      0.82        23\n",
      "      abcat0302037       0.76      0.57      0.65        23\n",
      "      abcat0401000       0.91      0.91      0.91        35\n",
      "      abcat0401001       0.33      0.25      0.29        20\n",
      "      abcat0409000       0.55      0.68      0.61        40\n",
      "      abcat0409001       0.88      0.81      0.85        37\n",
      "      abcat0410000       0.42      0.43      0.43        65\n",
      "      abcat0410012       0.50      0.72      0.59        25\n",
      "      abcat0410020       0.85      0.44      0.58        64\n",
      "      abcat0410022       0.31      0.26      0.28        35\n",
      "      abcat0410045       0.75      0.42      0.54        36\n",
      "      abcat0503000       0.79      0.55      0.65        42\n",
      "      abcat0504001       0.83      0.57      0.68        35\n",
      "      abcat0504010       0.67      0.73      0.70        63\n",
      "      abcat0507000       0.37      0.68      0.47        68\n",
      "      abcat0508000       0.66      0.76      0.70        74\n",
      "      abcat0509000       0.39      0.96      0.56        23\n",
      "      abcat0513004       0.90      0.90      0.90        20\n",
      "      abcat0515000       0.23      0.26      0.24        35\n",
      "      abcat0515013       0.40      0.09      0.14        23\n",
      "      abcat0515028       0.40      0.91      0.55        82\n",
      "      abcat0515042       0.39      0.75      0.51        24\n",
      "      abcat0700000       0.73      0.61      0.67        57\n",
      "      abcat0701002       0.83      0.87      0.85        39\n",
      "      abcat0703002       0.44      0.89      0.58        35\n",
      "      abcat0706000       0.94      0.73      0.82        22\n",
      "      abcat0707002       0.92      1.00      0.96        34\n",
      "      abcat0712000       0.53      0.42      0.47        24\n",
      "      abcat0715000       0.55      0.29      0.37        21\n",
      "      abcat0800000       0.75      0.67      0.71        49\n",
      "      abcat0802000       0.89      0.30      0.44        27\n",
      "      abcat0805000       0.68      0.47      0.56        32\n",
      "      abcat0807001       0.87      0.87      0.87        99\n",
      "      abcat0807009       0.93      0.86      0.89        64\n",
      "      abcat0809000       0.21      0.48      0.29        27\n",
      "      abcat0809002       0.87      0.92      0.89        37\n",
      "      abcat0809004       0.53      0.61      0.57        28\n",
      "      abcat0811002       0.54      0.25      0.34        56\n",
      "      abcat0811004       0.39      0.34      0.37        44\n",
      "      abcat0811006       0.87      0.83      0.85       361\n",
      "      abcat0811007       0.52      0.71      0.60        68\n",
      "      abcat0811011       0.43      0.55      0.48        22\n",
      "      abcat0900000       0.81      0.65      0.72        20\n",
      "      abcat0901000       0.29      0.75      0.42        56\n",
      "      abcat0902000       0.61      0.70      0.66        27\n",
      "      abcat0904001       0.94      0.88      0.91        51\n",
      "      abcat0904004       0.56      1.00      0.72        23\n",
      "      abcat0905001       0.89      0.96      0.93        52\n",
      "      abcat0907001       0.75      0.67      0.71        27\n",
      "      abcat0907006       0.83      0.81      0.82        48\n",
      "      abcat0907007       0.65      0.47      0.55        32\n",
      "      abcat0908001       0.27      0.39      0.32        23\n",
      "      abcat0908003       0.94      0.57      0.71        28\n",
      "      abcat0910001       0.74      0.96      0.83        26\n",
      "      abcat0911000       0.69      0.84      0.76        67\n",
      "      abcat0912000       0.48      0.40      0.44        73\n",
      "      abcat0912005       0.43      0.45      0.44        20\n",
      "      abcat0912008       1.00      0.62      0.76        21\n",
      "      abcat0912012       0.89      0.57      0.69        30\n",
      "      abcat0912014       0.67      0.10      0.17        21\n",
      "      abcat0912018       1.00      0.74      0.85        39\n",
      "      abcat0912020       0.64      0.75      0.69        24\n",
      "      abcat0912023       1.00      0.66      0.79        29\n",
      "      abcat0912025       0.45      0.44      0.45        43\n",
      "      abcat0915000       1.00      0.29      0.45        41\n",
      "      abcat0915005       0.82      0.48      0.61        29\n",
      "      abcat0915009       0.75      0.09      0.16        34\n",
      "      abcat0916000       0.38      0.53      0.45        62\n",
      "      abcat0916008       0.37      0.42      0.40        38\n",
      "          cat09000       0.98      0.97      0.97        91\n",
      "             other       0.32      0.35      0.34       538\n",
      "pcmcat128500050004       0.78      0.17      0.29        40\n",
      "pcmcat138500050001       1.00      0.60      0.75        30\n",
      "pcmcat143000050007       0.85      0.86      0.86        74\n",
      "pcmcat143200050025       1.00      0.08      0.15        25\n",
      "pcmcat143400050013       0.79      0.80      0.79        74\n",
      "pcmcat144700050004       0.00      0.00      0.00        26\n",
      "pcmcat151600050008       0.72      0.34      0.46        38\n",
      "pcmcat151600050027       0.88      0.71      0.79        21\n",
      "pcmcat151600050037       0.62      0.84      0.71        19\n",
      "pcmcat152100050010       0.43      0.70      0.53        33\n",
      "pcmcat152100050020       0.32      0.40      0.36        55\n",
      "pcmcat152100050027       0.32      0.38      0.35        32\n",
      "pcmcat152100050035       0.17      0.12      0.14        33\n",
      "pcmcat152100050038       0.58      0.53      0.55        36\n",
      "pcmcat152200050014       0.00      0.00      0.00        20\n",
      "pcmcat156300050006       0.24      0.28      0.26        32\n",
      "pcmcat158900050018       0.94      0.68      0.79        25\n",
      "pcmcat158900050019       0.92      1.00      0.96        22\n",
      "pcmcat159300050002       0.74      0.81      0.77        21\n",
      "pcmcat165900050023       0.30      0.11      0.16        28\n",
      "pcmcat165900050032       0.41      0.33      0.37        21\n",
      "pcmcat165900050033       0.66      0.90      0.76       148\n",
      "pcmcat165900050034       0.56      0.59      0.57        34\n",
      "pcmcat171900050024       0.31      0.45      0.37        20\n",
      "pcmcat171900050026       1.00      0.05      0.09        21\n",
      "pcmcat171900050031       0.82      0.56      0.67        25\n",
      "pcmcat179200050003       0.92      0.39      0.55        31\n",
      "pcmcat179200050008       0.76      0.58      0.66        45\n",
      "pcmcat179200050013       0.92      0.60      0.73        20\n",
      "pcmcat180700050008       0.75      0.55      0.63        22\n",
      "pcmcat183800050006       0.80      0.92      0.86        52\n",
      "pcmcat183800050007       0.83      0.45      0.59        22\n",
      "pcmcat186100050005       0.33      0.67      0.44        21\n",
      "pcmcat191200050015       0.64      0.19      0.29        37\n",
      "pcmcat194000050018       0.43      0.64      0.52        25\n",
      "pcmcat194000050022       0.55      0.30      0.38        61\n",
      "pcmcat194000050023       0.81      0.74      0.77        23\n",
      "pcmcat195200050001       0.50      0.05      0.10        19\n",
      "pcmcat196400050015       0.87      0.98      0.92        56\n",
      "pcmcat196400050016       0.95      0.92      0.93        60\n",
      "pcmcat200900050014       0.00      0.00      0.00        31\n",
      "pcmcat202800050013       0.65      0.90      0.75       124\n",
      "pcmcat207200050007       0.67      0.79      0.73        42\n",
      "pcmcat209000050006       0.93      0.74      0.82        19\n",
      "pcmcat209000050008       0.56      0.88      0.68        43\n",
      "pcmcat209400050001       0.92      0.67      0.77        33\n",
      "pcmcat210000050008       0.38      0.67      0.48        36\n",
      "pcmcat210900050000       1.00      0.37      0.54        19\n",
      "pcmcat210900050001       0.23      0.90      0.37        21\n",
      "pcmcat214700050000       0.72      0.92      0.80       284\n",
      "pcmcat219100050010       0.73      0.79      0.76        34\n",
      "pcmcat221100050003       1.00      0.05      0.10        20\n",
      "pcmcat225800050009       0.50      0.65      0.57        20\n",
      "pcmcat226900050013       0.91      0.31      0.46        97\n",
      "pcmcat232900050000       0.82      0.75      0.78        24\n",
      "pcmcat232900050017       0.99      0.92      0.95       711\n",
      "pcmcat232900050030       0.00      0.00      0.00        23\n",
      "pcmcat232900050031       0.55      0.88      0.68        26\n",
      "pcmcat233000050008       0.34      0.87      0.49        30\n",
      "pcmcat240500050052       0.70      0.26      0.38        27\n",
      "pcmcat240500050057       0.29      0.14      0.19        28\n",
      "pcmcat241600050001       0.14      0.17      0.15        24\n",
      "pcmcat242000050002       0.79      0.45      0.57       103\n",
      "pcmcat242800050021       1.00      0.03      0.06        35\n",
      "pcmcat244200050008       0.50      0.37      0.43        27\n",
      "pcmcat247400050000       0.72      0.98      0.83        51\n",
      "pcmcat248300050003       1.00      0.31      0.47        29\n",
      "pcmcat249700050006       0.30      0.28      0.29        25\n",
      "pcmcat251300050004       0.72      0.38      0.50        69\n",
      "pcmcat251500050009       0.53      0.42      0.47        24\n",
      "pcmcat251600050003       0.25      0.10      0.14        20\n",
      "pcmcat252700050006       0.65      0.40      0.49        55\n",
      "pcmcat254000050002       0.39      0.42      0.40        57\n",
      "pcmcat258900050003       0.61      0.83      0.70        23\n",
      "pcmcat258900050007       0.71      0.19      0.29        27\n",
      "pcmcat266500050030       0.80      0.90      0.85        40\n",
      "pcmcat268100050002       0.29      0.64      0.40        28\n",
      "pcmcat272800050000       0.56      0.86      0.68        29\n",
      "pcmcat284400050091       0.75      0.57      0.65        21\n",
      "pcmcat284800050006       0.12      0.04      0.06        27\n",
      "pcmcat284800050007       0.59      0.75      0.66        44\n",
      "pcmcat286300050020       0.72      0.72      0.72        25\n",
      "pcmcat296300050018       0.71      0.94      0.81        51\n",
      "pcmcat300300050002       0.40      0.32      0.35        19\n",
      "pcmcat303600050001       0.65      0.78      0.71        36\n",
      "pcmcat303600050005       0.84      0.86      0.85        43\n",
      "pcmcat303700050016       0.58      0.33      0.42        21\n",
      "pcmcat306400050032       0.79      0.90      0.84        49\n",
      "pcmcat308100050020       0.55      0.67      0.60        27\n",
      "pcmcat309300050002       0.56      0.62      0.59        29\n",
      "pcmcat309300050003       0.00      0.00      0.00        20\n",
      "pcmcat309900050001       0.34      0.46      0.39        57\n",
      "pcmcat310200050004       0.62      0.59      0.60       135\n",
      "pcmcat311200050005       0.82      0.72      0.77        58\n",
      "pcmcat312300050015       0.44      0.39      0.41        31\n",
      "pcmcat324200050004       0.65      0.81      0.72        21\n",
      "pcmcat326000050010       0.44      0.72      0.55        68\n",
      "pcmcat326000050011       0.74      0.96      0.83        47\n",
      "pcmcat328900050008       0.75      0.27      0.40        33\n",
      "pcmcat331200050000       0.79      0.32      0.46        34\n",
      "pcmcat331200050001       0.32      0.86      0.46        36\n",
      "pcmcat331600050007       0.31      0.47      0.37        51\n",
      "pcmcat332100050000       0.65      0.88      0.75        80\n",
      "pcmcat335400050008       0.94      0.96      0.95        47\n",
      "pcmcat338200050008       0.68      0.79      0.73        19\n",
      "pcmcat340500050007       0.87      0.83      0.85        24\n",
      "pcmcat344400050007       0.42      0.63      0.50        52\n",
      "pcmcat350800050010       0.93      0.83      0.88        47\n",
      "pcmcat352500050007       0.68      0.36      0.47        36\n",
      "pcmcat367400050001       0.64      0.21      0.31       135\n",
      "pcmcat367400050002       0.72      0.47      0.57        45\n",
      "pcmcat369900050001       0.64      0.23      0.34        30\n",
      "pcmcat373300050003       0.68      0.57      0.62        23\n",
      "pcmcat374500050006       0.00      0.00      0.00        17\n",
      "pcmcat377500050003       0.73      0.73      0.73        26\n",
      "pcmcat748300322875       0.80      0.83      0.82        24\n",
      "pcmcat748300579994       0.00      0.00      0.00        24\n",
      "pcmcat748300580023       0.52      0.55      0.53        42\n",
      "pcmcat748301695443       0.76      0.69      0.72        36\n",
      "pcmcat748301803023       0.92      0.82      0.87        57\n",
      "\n",
      "          accuracy                           0.61     10006\n",
      "         macro avg       0.60      0.55      0.54     10006\n",
      "      weighted avg       0.64      0.61      0.60     10006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell\n",
    "\n",
    "print(classification_report(y_true=labels, y_pred=predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2379d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories\n",
      "├── pcmcat312300050015\n",
      "│   ├── pcmcat248700050021\n",
      "│   │   ├── pcmcat303600050001\n",
      "│   │   └── pcmcat179100050006\n",
      "│   │       ├── pcmcat179200050003\n",
      "│   │       ├── pcmcat179200050008\n",
      "│   │       │   └── pcmcat748300322875\n",
      "│   │       └── pcmcat179200050013\n",
      "│   ├── abcat0802000\n",
      "│   │   ├── abcat0811011\n",
      "│   │   └── abcat0802001\n",
      "│   │       └── pcmcat159300050002\n",
      "│   ├── abcat0805000\n",
      "│   │   └── abcat0511001\n",
      "│   │       └── pcmcat266500050030\n",
      "│   ├── pcmcat275600050000\n",
      "│   │   └── abcat0807000\n",
      "│   │       ├── abcat0807001\n",
      "│   │       ├── pcmcat335400050008\n",
      "│   │       └── abcat0807009\n",
      "│   ├── abcat0809000\n",
      "│   │   ├── abcat0809004\n",
      "│   │   └── abcat0809002\n",
      "│   ├── pcmcat249700050006\n",
      "│   │   ├── pcmcat219100050010\n",
      "│   │   ├── pcmcat286300050020\n",
      "│   │   └── pcmcat272800050000\n",
      "│   ├── pcmcat254000050002\n",
      "│   │   └── pcmcat308100050020\n",
      "│   │       └── pcmcat340500050007\n",
      "│   └── pcmcat341100050005\n",
      "│       └── pcmcat253700050018\n",
      "│           └── pcmcat248300050003\n",
      "├── other\n",
      "├── abcat0300000\n",
      "│   ├── pcmcat165900050023\n",
      "│   │   └── pcmcat331600050007\n",
      "│   │       └── pcmcat165900050031\n",
      "│   │           ├── pcmcat165900050033\n",
      "│   │           ├── pcmcat165900050034\n",
      "│   │           └── pcmcat165900050032\n",
      "│   ├── abcat0302000\n",
      "│   │   ├── abcat0302034\n",
      "│   │   │   └── abcat0302037\n",
      "│   │   ├── abcat0302001\n",
      "│   │   ├── abcat0302012\n",
      "│   │   └── abcat0302005\n",
      "│   ├── pcmcat156300050006\n",
      "│   └── abcat0301000\n",
      "├── abcat0207000\n",
      "│   ├── pcmcat152100050020\n",
      "│   ├── abcat0208024\n",
      "│   │   └── pcmcat151600050008\n",
      "│   ├── pcmcat152100050035\n",
      "│   │   └── pcmcat251600050003\n",
      "│   │       └── pcmcat152100050038\n",
      "│   ├── pcmcat151600050037\n",
      "│   ├── pcmcat152100050027\n",
      "│   ├── pcmcat152200050014\n",
      "│   │   ├── pcmcat202800050013\n",
      "│   │   └── pcmcat251500050009\n",
      "│   ├── pcmcat152100050010\n",
      "│   └── pcmcat151600050019\n",
      "│       └── pcmcat221400050011\n",
      "│           └── pcmcat151600050027\n",
      "├── pcmcat252700050006\n",
      "│   ├── pcmcat244200050008\n",
      "│   ├── pcmcat284400050091\n",
      "│   └── pcmcat369900050001\n",
      "├── abcat0700000\n",
      "│   ├── abcat0706000\n",
      "│   ├── abcat0701000\n",
      "│   │   └── abcat0701002\n",
      "│   ├── pcmcat232900050017\n",
      "│   ├── abcat0707000\n",
      "│   │   └── abcat0707002\n",
      "│   ├── abcat0703000\n",
      "│   │   └── abcat0703002\n",
      "│   ├── abcat0712000\n",
      "│   ├── pcmcat232900050000\n",
      "│   ├── abcat0715000\n",
      "│   ├── pcmcat295700050012\n",
      "│   │   └── pcmcat296300050018\n",
      "│   ├── pcmcat300300050002\n",
      "│   │   └── pcmcat303600050005\n",
      "│   └── pcmcat306400050032\n",
      "├── abcat0400000\n",
      "│   ├── abcat0401000\n",
      "│   │   └── abcat0401001\n",
      "│   │       └── pcmcat324200050004\n",
      "│   ├── abcat0410022\n",
      "│   │   └── pcmcat329700050009\n",
      "│   │       └── pcmcat240500050057\n",
      "│   ├── abcat0410000\n",
      "│   │   ├── abcat0410018\n",
      "│   │   │   ├── pcmcat233000050008\n",
      "│   │   │   │   └── pcmcat195200050001\n",
      "│   │   │   └── pcmcat374500050006\n",
      "│   │   ├── abcat0410020\n",
      "│   │   ├── abcat0410012\n",
      "│   │   │   └── pcmcat284800050007\n",
      "│   │   ├── pcmcat284800050006\n",
      "│   │   │   └── abcat0410001\n",
      "│   │   │       └── pcmcat328900050008\n",
      "│   │   ├── abcat0410045\n",
      "│   │   └── pcmcat240500050025\n",
      "│   │       └── pcmcat240500050052\n",
      "│   ├── abcat0404000\n",
      "│   │   └── pcmcat225800050009\n",
      "│   └── abcat0409000\n",
      "│       └── abcat0409001\n",
      "├── abcat0500000\n",
      "│   ├── abcat0515000\n",
      "│   │   ├── abcat0515042\n",
      "│   │   ├── pcmcat221100050003\n",
      "│   │   ├── abcat0515025\n",
      "│   │   │   ├── pcmcat183800050007\n",
      "│   │   │   ├── pcmcat183800050006\n",
      "│   │   │   └── abcat0515028\n",
      "│   │   ├── abcat0513000\n",
      "│   │   │   ├── pcmcat338200050008\n",
      "│   │   │   └── abcat0513004\n",
      "│   │   ├── abcat0504001\n",
      "│   │   │   └── pcmcat186100050005\n",
      "│   │   ├── abcat0504010\n",
      "│   │   └── abcat0515012\n",
      "│   │       └── abcat0515013\n",
      "│   ├── abcat0507000\n",
      "│   ├── pcmcat309900050001\n",
      "│   │   └── pcmcat242000050002\n",
      "│   │       └── pcmcat344400050007\n",
      "│   ├── abcat0509000\n",
      "│   │   └── pcmcat200900050014\n",
      "│   ├── abcat0508000\n",
      "│   ├── pcmcat209000050006\n",
      "│   │   └── pcmcat209000050008\n",
      "│   ├── abcat0503000\n",
      "│   ├── abcat0502000\n",
      "│   │   └── pcmcat138500050001\n",
      "│   │       └── pcmcat247400050000\n",
      "│   └── abcat0501000\n",
      "│       └── pcmcat143400050013\n",
      "├── abcat0900000\n",
      "│   ├── abcat0904000\n",
      "│   │   ├── abcat0904001\n",
      "│   │   ├── abcat0904004\n",
      "│   │   │   └── pcmcat180700050008\n",
      "│   │   ├── abcat0904003\n",
      "│   │   │   ├── pcmcat196400050015\n",
      "│   │   │   └── pcmcat196400050016\n",
      "│   │   └── abcat0904002\n",
      "│   │       └── pcmcat207200050007\n",
      "│   ├── abcat0912000\n",
      "│   │   ├── pcmcat367400050002\n",
      "│   │   │   ├── pcmcat367400050005\n",
      "│   │   │   │   └── abcat0912008\n",
      "│   │   │   ├── abcat0912005\n",
      "│   │   │   │   └── pcmcat258900050007\n",
      "│   │   │   └── pcmcat367400050003\n",
      "│   │   │       └── pcmcat194000050023\n",
      "│   │   ├── abcat0912011\n",
      "│   │   │   └── pcmcat194000050018\n",
      "│   │   │       └── pcmcat258900050003\n",
      "│   │   ├── abcat0912014\n",
      "│   │   ├── abcat0912025\n",
      "│   │   │   └── pcmcat251300050004\n",
      "│   │   ├── abcat0912023\n",
      "│   │   ├── abcat0912012\n",
      "│   │   ├── abcat0912020\n",
      "│   │   ├── pcmcat748301695371\n",
      "│   │   │   ├── pcmcat226900050013\n",
      "│   │   │   └── pcmcat748301695443\n",
      "│   │   ├── abcat0912018\n",
      "│   │   └── pcmcat194000050022\n",
      "│   ├── abcat0902000\n",
      "│   ├── pcmcat302300050021\n",
      "│   │   ├── abcat0907001\n",
      "│   │   ├── abcat0907007\n",
      "│   │   ├── abcat0908003\n",
      "│   │   ├── abcat0908001\n",
      "│   │   ├── pcmcat268100050002\n",
      "│   │   └── abcat0907006\n",
      "│   ├── abcat0901000\n",
      "│   │   └── pcmcat367400050001\n",
      "│   ├── abcat0903000\n",
      "│   │   └── pcmcat748301803023\n",
      "│   ├── abcat0910000\n",
      "│   │   ├── abcat0910004\n",
      "│   │   │   ├── pcmcat232900050031\n",
      "│   │   │   └── pcmcat232900050030\n",
      "│   │   └── abcat0910001\n",
      "│   ├── abcat0911000\n",
      "│   ├── abcat0905000\n",
      "│   │   └── abcat0905001\n",
      "│   └── abcat0916000\n",
      "│       ├── pcmcat303700050016\n",
      "│       └── abcat0916008\n",
      "├── abcat0200000\n",
      "│   ├── abcat0204000\n",
      "│   │   ├── pcmcat144700050004\n",
      "│   │   ├── pcmcat143000050011\n",
      "│   │   │   ├── pcmcat331200050001\n",
      "│   │   │   └── pcmcat331200050000\n",
      "│   │   └── pcmcat143000050007\n",
      "│   ├── pcmcat241600050001\n",
      "│   │   ├── pcmcat309300050002\n",
      "│   │   ├── abcat0205000\n",
      "│   │   │   ├── abcat0205006\n",
      "│   │   │   ├── pcmcat210900050000\n",
      "│   │   │   │   └── pcmcat210900050001\n",
      "│   │   │   └── abcat0205001\n",
      "│   │   ├── abcat0203000\n",
      "│   │   │   └── abcat0205007\n",
      "│   │   └── pcmcat309300050003\n",
      "│   ├── abcat0208007\n",
      "│   ├── pcmcat310200050004\n",
      "│   └── abcat0208000\n",
      "│       └── abcat0208015\n",
      "├── abcat0100000\n",
      "│   ├── abcat0106000\n",
      "│   │   ├── pcmcat332100050008\n",
      "│   │   │   └── pcmcat158900050019\n",
      "│   │   ├── abcat0106004\n",
      "│   │   ├── abcat0106001\n",
      "│   │   │   └── pcmcat332100050000\n",
      "│   │   └── abcat0106010\n",
      "│   ├── abcat0107000\n",
      "│   │   └── abcat0107015\n",
      "│   ├── abcat0101000\n",
      "│   │   └── abcat0101001\n",
      "│   └── pcmcat158900050008\n",
      "│       └── pcmcat158900050018\n",
      "├── pcmcat242800050021\n",
      "│   ├── abcat0915000\n",
      "│   │   ├── abcat0915009\n",
      "│   │   └── abcat0915005\n",
      "│   ├── pcmcat352500050007\n",
      "│   ├── abcat0301006\n",
      "│   └── pcmcat210000050008\n",
      "├── pcmcat128500050004\n",
      "├── abcat0800000\n",
      "│   ├── abcat0811002\n",
      "│   │   ├── abcat0811006\n",
      "│   │   ├── pcmcat191200050015\n",
      "│   │   │   └── pcmcat214700050000\n",
      "│   │   │       ├── pcmcat748300579994\n",
      "│   │   │       └── pcmcat748300580023\n",
      "│   │   ├── abcat0811004\n",
      "│   │   │   ├── pcmcat326000050010\n",
      "│   │   │   └── pcmcat326000050011\n",
      "│   │   ├── pcmcat373300050003\n",
      "│   │   ├── abcat0811007\n",
      "│   │   │   ├── pcmcat171900050026\n",
      "│   │   │   └── pcmcat171900050024\n",
      "│   │   ├── pcmcat171900050031\n",
      "│   │   └── pcmcat321000050003\n",
      "│   │       └── pcmcat321000050005\n",
      "│   │           └── pcmcat350800050010\n",
      "│   ├── pcmcat156400050037\n",
      "│   │   └── pcmcat311200050005\n",
      "│   └── pcmcat209400050001\n",
      "├── cat09000\n",
      "├── pcmcat139900050002\n",
      "│   └── pcmcat748300660981\n",
      "│       └── pcmcat143200050025\n",
      "└── pcmcat332000050000\n",
      "    └── pcmcat748300489081\n",
      "        └── pcmcat377500050002\n",
      "            └── pcmcat377500050003\n"
     ]
    }
   ],
   "source": [
    "cat = build_df(json_path='/home/app/src/data/products.json', \n",
    "             threshold=100, \n",
    "             preprocessed_csv='/home/app/src/data/normalized_data.csv'\n",
    "            ) \n",
    "\n",
    "y = cat['leaf']\n",
    "\n",
    "tree_dict = tree_utils.make_tree(cat, cat['category'], 'Categories', display_tree= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d95fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/app/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.6102338596841895\n",
      "Precision: 0.6102338596841895\n",
      "Recall: 0.6102338596841895\n",
      "F1 Score: 0.6102338596841895\n",
      "Average distance between nodes categories: 1.0107935238856687\n",
      "Top 5 Score: 0.8203078153108135\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "                      3D Printer Filament       0.94      0.96      0.95        47\n",
      "                  A/V Cables & Connectors       0.48      0.55      0.51        78\n",
      "                  Action Camcorder Mounts       0.29      0.14      0.19        28\n",
      "           Activity Trackers & Pedometers       0.38      0.67      0.48        36\n",
      "              Adapters, Cables & Chargers       0.52      0.71      0.60        68\n",
      "                         Air Conditioners       0.75      0.67      0.71        27\n",
      "             Air Purifier Filters & Parts       0.58      0.33      0.42        21\n",
      "                            Air Purifiers       0.27      0.39      0.32        23\n",
      "               All Cell Phones with Plans       0.92      0.67      0.77        33\n",
      "                             All Desktops       0.79      0.80      0.79        74\n",
      "                       All Flat-Panel TVs       0.78      0.56      0.65        25\n",
      "                           All Headphones       0.00      0.00      0.00        26\n",
      "                              All Laptops       1.00      0.60      0.75        30\n",
      "                         All Memory Cards       0.50      0.65      0.57        20\n",
      "                           All Microwaves       0.92      0.82      0.87        57\n",
      "                All Point & Shoot Cameras       0.65      0.81      0.72        21\n",
      "                             All Printers       0.80      0.90      0.85        40\n",
      "                        All Refrigerators       0.64      0.21      0.31       135\n",
      "                            All TV Stands       0.65      0.88      0.75        80\n",
      "                              All Tablets       0.56      0.88      0.68        43\n",
      "                 All Unlocked Cell Phones       0.82      0.72      0.77        58\n",
      "                      Antennas & Adapters       0.41      0.33      0.37        21\n",
      "               Apple Watch Bands & Straps       0.73      0.73      0.73        26\n",
      "            Appliance Parts & Accessories       0.38      0.53      0.45        62\n",
      "                               Appliances       0.81      0.65      0.72        20\n",
      "                                    Audio       0.44      0.50      0.47        22\n",
      "                                 Bakeware       0.76      0.69      0.72        36\n",
      "                      Best Buy Gift Cards       0.98      0.97      0.97        91\n",
      "                               Binoculars       0.88      0.81      0.85        37\n",
      "          Binoculars, Telescopes & Optics       0.55      0.68      0.61        40\n",
      "                                 Blenders       0.43      0.64      0.52        25\n",
      "            Bluetooth & Wireless Speakers       0.62      0.59      0.60       135\n",
      "                       Bookshelf Speakers       0.12      0.21      0.15        24\n",
      "                     Built-In Dishwashers       0.89      0.96      0.93        52\n",
      "                   CD & DVD Media Storage       0.19      0.42      0.26        24\n",
      "                  CD Players & Turntables       0.00      0.00      0.00        20\n",
      "                    Camcorder Accessories       0.31      0.26      0.28        35\n",
      "              Camera Bags, Cases & Straps       0.12      0.04      0.06        27\n",
      "                         Camera Batteries       0.59      0.75      0.66        44\n",
      "                 Camera Batteries & Power       0.50      0.72      0.59        25\n",
      "                           Car Amplifiers       0.63      0.71      0.67        24\n",
      "             Car Audio Installation Parts       0.31      0.47      0.37        51\n",
      "                             Car Chargers       0.31      0.45      0.37        20\n",
      "                    Car Electronics & GPS       0.24      0.21      0.22        43\n",
      "     Car Installation Parts & Accessories       0.30      0.11      0.16        28\n",
      "                             Car Speakers       0.71      0.44      0.55        27\n",
      "                     Car Stereo Receivers       0.75      0.91      0.82        23\n",
      "                           Car Subwoofers       0.76      0.57      0.65        23\n",
      "                                    Cases       0.42      0.63      0.50        52\n",
      "          Cases, Covers & Keyboard Folios       0.79      0.45      0.57       103\n",
      "                   Cell Phone Accessories       0.54      0.25      0.34        56\n",
      "             Cell Phone Batteries & Power       0.39      0.34      0.37        44\n",
      "                 Cell Phone Cases & Clips       0.87      0.83      0.85       361\n",
      "                              Cell Phones       0.75      0.67      0.71        49\n",
      "                            Coffee Makers       0.43      0.45      0.44        20\n",
      "                              Coffee Pods       1.00      0.62      0.76        21\n",
      "                   Coffee, Tea & Espresso       0.72      0.47      0.57        45\n",
      "       Computer Accessories & Peripherals       0.23      0.26      0.24        35\n",
      "              Computer Cards & Components       0.37      0.68      0.47        68\n",
      "                       Computer Keyboards       0.90      0.90      0.90        20\n",
      "                           Connected Home       0.39      0.42      0.40        57\n",
      "              Connected Home & Housewares       0.44      0.39      0.41        31\n",
      "                                 Cooktops       0.94      0.88      0.91        51\n",
      "                                 Cookware       0.91      0.31      0.46        97\n",
      "                  DJ & Lighting Equipment       0.32      0.38      0.35        32\n",
      "                              DSLR Lenses       0.34      0.87      0.49        30\n",
      "                   Dash Installation Kits       0.66      0.90      0.76       148\n",
      "                           Deck Harnesses       0.56      0.59      0.57        34\n",
      "                                    Desks       0.53      0.61      0.57        28\n",
      "               Digital Camera Accessories       0.42      0.43      0.43        65\n",
      "                          Digital Cameras       0.91      0.91      0.91        35\n",
      "                     Drones & Accessories       0.64      0.23      0.34        30\n",
      "                       Drums & Percussion       0.43      0.70      0.53        33\n",
      "               Earbud & In-Ear Headphones       0.85      0.86      0.86        74\n",
      "                          Electric Dryers       0.55      0.88      0.68        26\n",
      "            Electric Griddles & Hotplates       0.67      0.10      0.17        21\n",
      "                          Electric Ranges       0.95      0.92      0.93        60\n",
      "                     Electric Tea Kettles       0.81      0.74      0.77        23\n",
      "                     External Hard Drives       0.33      0.67      0.44        21\n",
      "                                     Fans       0.83      0.81      0.82        48\n",
      "                    Filters & Accessories       0.85      0.44      0.58        64\n",
      "                               Fireplaces       0.29      0.64      0.40        28\n",
      "                    Fitness & GPS Watches       0.48      0.79      0.60        38\n",
      "                    Flashes & Accessories       0.70      0.26      0.38        27\n",
      "                Food Preparation Utensils       0.72      0.38      0.50        69\n",
      "                    Freezers & Ice Makers       0.61      0.70      0.66        27\n",
      "                       Full-Size Blenders       0.61      0.83      0.70        23\n",
      "                        Furniture & Decor       0.30      0.28      0.29        25\n",
      "             GPS Navigation & Accessories       0.00      0.00      0.00        32\n",
      "                Game Room & Bar Furniture       0.73      0.79      0.76        34\n",
      "                               Gas Dryers       0.00      0.00      0.00        23\n",
      "                               Gas Ranges       0.87      0.98      0.92        56\n",
      "                                   Grills       0.92      0.39      0.55        31\n",
      "                       Guitar Accessories       0.72      0.34      0.46        38\n",
      "                                Hair Care       0.75      0.09      0.16        34\n",
      "                    Hard Drives & Storage       0.83      0.57      0.68        35\n",
      "                               Headphones       0.44      0.43      0.44        37\n",
      "             Health & Fitness Accessories       0.68      0.36      0.47        36\n",
      "                 Health, Fitness & Beauty       1.00      0.03      0.06        35\n",
      "                                  Heaters       0.65      0.47      0.55        32\n",
      "                               Home Audio       0.14      0.17      0.15        24\n",
      "                      Household Batteries       0.65      0.78      0.71        36\n",
      "                              Humidifiers       0.94      0.57      0.71        28\n",
      "                      In-Ceiling Speakers       0.23      0.90      0.37        21\n",
      "            In-Wall & In-Ceiling Speakers       1.00      0.37      0.54        19\n",
      "           Instrument Instructional Books       0.53      0.42      0.47        24\n",
      "                       Internal Batteries       0.74      0.96      0.83        47\n",
      "                                Keyboards       0.62      0.84      0.71        19\n",
      "                          Kitchen Gadgets       0.45      0.44      0.45        43\n",
      "                             LED Monitors       0.00      0.00      0.00        31\n",
      "                      Laptop Bags & Cases       0.40      0.91      0.55        82\n",
      "                         Laptop Batteries       0.80      0.92      0.86        52\n",
      "               Laptop Chargers & Adapters       0.83      0.45      0.59        22\n",
      "                     Learning & Education       0.75      0.57      0.65        21\n",
      "                    Living Room Furniture       0.56      0.86      0.68        29\n",
      "                                  Luggage       1.00      0.31      0.47        29\n",
      "   Magnolia TV Stands, Mounts & Furniture       1.00      0.08      0.15        25\n",
      "                     Marine & Powersports       0.24      0.28      0.26        32\n",
      "                                     Mice       0.68      0.79      0.73        19\n",
      "                              Microphones       0.58      0.53      0.55        36\n",
      "                Microphones & Accessories       0.25      0.10      0.14        20\n",
      "                 Microphones & Live Sound       0.17      0.12      0.14        33\n",
      "                        Mirrorless Lenses       0.00      0.00      0.00        17\n",
      "               Mixers & Mixer Accessories       1.00      0.74      0.85        39\n",
      "             Monitor & Screen Accessories       1.00      0.05      0.10        20\n",
      "                                 Monitors       0.39      0.96      0.56        23\n",
      "                  Multi-Cup Coffee Makers       0.71      0.19      0.29        27\n",
      "           Musical Instrument Accessories       0.10      0.14      0.12        64\n",
      "                      Musical Instruments       0.52      0.69      0.59        70\n",
      "                              Name Brands       0.78      0.17      0.29        40\n",
      "                    Networking & Wireless       0.79      0.55      0.65        42\n",
      "                             Nintendo 3DS       0.82      0.75      0.78        24\n",
      "                        Nintendo DS Games       0.92      1.00      0.96        34\n",
      "                            Office Chairs       0.87      0.92      0.89        37\n",
      "                       Office Electronics       0.68      0.47      0.56        32\n",
      "               Office Furniture & Storage       0.21      0.48      0.29        27\n",
      "                        On-Ear Headphones       0.79      0.32      0.46        34\n",
      "                          Outdoor Heating       0.92      0.60      0.73        20\n",
      "                          Outdoor Seating       0.80      0.83      0.82        24\n",
      "                         Outdoor Speakers       0.58      0.58      0.58        31\n",
      "                      Over-Ear Headphones       0.32      0.86      0.46        36\n",
      "                                PC Gaming       0.53      0.42      0.47        24\n",
      "                               PC Laptops       0.72      0.98      0.83        51\n",
      "                                PS3 Games       0.44      0.89      0.58        35\n",
      "                                PS4 Games       0.71      0.94      0.81        51\n",
      "                  Patio Furniture & Decor       0.76      0.58      0.66        45\n",
      "                                   Pedals       0.88      0.71      0.79        21\n",
      "                   Personal Care & Beauty       1.00      0.29      0.45        41\n",
      "                  Photography Accessories       0.68      0.57      0.62        23\n",
      "                    Point & Shoot Cameras       0.33      0.25      0.29        20\n",
      "            Portable Chargers/Power Packs       0.44      0.72      0.55        68\n",
      "                          Pre-Owned Games       0.99      0.92      0.95       711\n",
      "                             Prime Lenses       0.50      0.05      0.10        19\n",
      "                              Printer Ink       0.87      0.87      0.87        99\n",
      "                        Projector Screens       0.92      1.00      0.96        22\n",
      "                               Projectors       0.94      0.68      0.79        25\n",
      "                   Receivers & Amplifiers       0.56      0.62      0.59        29\n",
      "                      Recording Equipment       0.32      0.40      0.36        55\n",
      "                            Refrigerators       0.29      0.75      0.42        56\n",
      "                        Screen Protectors       0.82      0.56      0.67        25\n",
      "                  Security Camera Systems       0.87      0.83      0.85        24\n",
      "          Security Cameras & Surveillance       0.55      0.67      0.60        27\n",
      "                       Shavers & Trimmers       0.82      0.48      0.61        29\n",
      "                              Sheet Music       0.65      0.90      0.75       124\n",
      "                       Sheet Music & DVDs       0.00      0.00      0.00        20\n",
      "                             Single Ovens       0.75      0.55      0.63        22\n",
      " Slow Cookers, Crock Pots & Roaster Ovens       0.89      0.57      0.69        30\n",
      "                 Small Kitchen Appliances       0.48      0.40      0.44        73\n",
      "                         Smartwatch Bands       0.93      0.83      0.88        47\n",
      "                                 Software       0.66      0.76      0.70        74\n",
      "                               Sound Bars       0.46      0.65      0.54        20\n",
      "                      Speaker Accessories       0.22      0.12      0.16        32\n",
      "                                 Speakers       1.00      0.14      0.24        59\n",
      "                     Specialty Appliances       0.55      0.30      0.38        61\n",
      "Steamers, Rice Cookers & Pressure Cookers       0.64      0.75      0.69        24\n",
      "                 Surge Protectors & Power       0.39      0.75      0.51        24\n",
      "                                  Systems       0.74      0.81      0.77        21\n",
      "                        TV & Home Theater       0.00      0.00      0.00        21\n",
      "            TV & Home Theater Accessories       0.35      0.27      0.31        41\n",
      "                                TV Mounts       0.38      0.75      0.50        44\n",
      "               TV, Movie & Character Toys       0.50      0.37      0.43        27\n",
      "                                      TVs       0.52      0.63      0.57        19\n",
      "                                  Tablets       0.93      0.74      0.82        19\n",
      "                    Telephone Accessories       0.43      0.55      0.48        22\n",
      "               Telephones & Communication       0.89      0.30      0.44        27\n",
      "                                 Toasters       1.00      0.66      0.79        29\n",
      "                                    Toner       0.93      0.86      0.89        64\n",
      "                             Toys to Life       0.79      0.90      0.84        49\n",
      "                     Toys, Games & Drones       0.65      0.40      0.49        55\n",
      "                       Tripods & Monopods       0.75      0.42      0.54        36\n",
      "                        USB Cables & Hubs       0.40      0.09      0.14        23\n",
      "                         USB Flash Drives       0.67      0.73      0.70        63\n",
      "            Universal Camera Bags & Cases       0.75      0.27      0.40        33\n",
      "          Vacuum & Floor Care Accessories       0.37      0.42      0.40        38\n",
      "             Vacuum Cleaners & Floor Care       0.69      0.84      0.76        67\n",
      "                   Video Game Accessories       0.55      0.29      0.37        21\n",
      "                              Video Games       0.73      0.61      0.67        57\n",
      "                                 Wall Art       0.72      0.72      0.72        25\n",
      "           Wall Chargers & Power Adapters       1.00      0.05      0.09        21\n",
      "                   Wall Mount Range Hoods       0.67      0.79      0.73        42\n",
      "                               Wall Ovens       0.56      1.00      0.72        23\n",
      "                         Washing Machines       0.74      0.96      0.83        26\n",
      "                                      Wii       0.94      0.73      0.82        22\n",
      "                           Xbox 360 Games       0.83      0.87      0.85        39\n",
      "                                 Xbox One       0.40      0.32      0.35        19\n",
      "                           Xbox One Games       0.84      0.86      0.85        43\n",
      "                iPad & Tablet Accessories       0.34      0.46      0.39        57\n",
      "                          iPhone 6s Cases       0.52      0.55      0.53        42\n",
      "                     iPhone 6s Plus Cases       0.00      0.00      0.00        24\n",
      "                       iPhone Accessories       0.64      0.19      0.29        37\n",
      "                     iPhone Cases & Clips       0.72      0.92      0.80       284\n",
      "            iPod & MP3 Player Accessories       0.17      0.04      0.06        28\n",
      "                                    other       0.32      0.35      0.34       538\n",
      "\n",
      "                                 accuracy                           0.61     10006\n",
      "                                macro avg       0.60      0.55      0.54     10006\n",
      "                             weighted avg       0.64      0.61      0.60     10006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation.get_performance(model=cnn_model,\n",
    "                           pred_labels=predictions, \n",
    "                           true_labels=labels,\n",
    "                           probs=probs,\n",
    "                           average='micro',\n",
    "                           tree= tree_dict,\n",
    "                           vectorizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8342c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model accuracy is 0.6102!\n"
     ]
    }
   ],
   "source": [
    "# (!) Don't touch this cell\n",
    "\n",
    "acc = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "\n",
    "print(f\"Your model accuracy is {acc:.4f}!\")\n",
    "\n",
    "if acc < .3:\n",
    "    raise ValueError(\"Your model accuracy is too low :(\\nYou can do it better! :)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f652b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee5563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9deea79bfd8769c20cdb41e577c31349975f53057f7c4a88718c49dab3f025eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
